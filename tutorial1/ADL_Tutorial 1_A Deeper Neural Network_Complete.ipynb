{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43d73f0",
   "metadata": {},
   "source": [
    "# Programming a deep feed-forward network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d5f1fc",
   "metadata": {},
   "source": [
    "This notebook is based on a fabulous [Kaggle tutorial by DATAI](https://www.kaggle.com/kanncaa1/deep-learning-tutorial-for-beginners) and uses the \"sign language digits data set\", also found through the link.\n",
    "\n",
    "We start by loading the relevant packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d5101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb4243e",
   "metadata": {},
   "source": [
    "## 1. The dataset (this part is identical to the logistic regression exercise)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9f83c1",
   "metadata": {},
   "source": [
    "The dataset contains 64x64 images of the signs used to represent the ten digits, 0-9. Indexes 204 to 408 of the dataset show the sign for zero and indexes 822 to 1027 show the sign for one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb919a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.load('digits_X.npy')\n",
    "y = np.load('digits_y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49065d90",
   "metadata": {},
   "source": [
    "Each value of `X` is a matrix with pixel values, while each value of `y` is a vector representing the value of the digit (one-hot encoded):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a55935d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411, 64, 64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e32a988f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(433, 64, 64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[204].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a21b785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[204]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c006c",
   "metadata": {},
   "source": [
    "We can, of course, display the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4da45e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 63.5, 63.5, -0.5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_size = 64\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(X[204].reshape(img_size, img_size))\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(X[822].reshape(img_size, img_size))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc147df",
   "metadata": {},
   "source": [
    "We only need the zeros and ones for our purposes. Hence, start by gathering only the relevant X-variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3b43afbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 64, 64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X[204:409], X[822:1028] ), axis=0)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0267609e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 64, 64), dtype=float32)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[822:1028]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55819fbd",
   "metadata": {},
   "source": [
    "For the ys, we also only want the relevant ones. Moreover, we want to make sure that instead of a vector, we simply have 0 if the digit is zero and 1 if it is one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5c2ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros(409-204)\n",
    "o = np.ones(1028-822)\n",
    "y = np.concatenate((z, o), axis=0).reshape(X.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d247facb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0d9dbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298d019",
   "metadata": {},
   "source": [
    "With the `reshape`, we make sure that `y` is a vector with two dimensions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60642dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(411, 64, 64)\n",
      "(411, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca75ea4",
   "metadata": {},
   "source": [
    "Next, we split the data into training and testing with 15% in the test set (you know the drill):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf7efc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 64, 64)\n",
      "(349, 1)\n",
      "(62, 64, 64)\n",
      "(62, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=172)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d622c30e",
   "metadata": {},
   "source": [
    "Finally, we need to \"flatten\" the Xs. Currently, our input is three-dimensional (each observation is a matrix). However, when we run regressions (or train models more generally), we usually have two-dimensional inputs, as it makes things a lot easier to work with. There are exceptions to this of course, specifically when using convolutional neural networks, but let's not get ahead of ourselves.\n",
    "\n",
    "What we will do is to convert each matrix (each observation's X-value) to a vector, simply by stacking all the columns of the matrix. If $X^{(i)} \\in \\mathcal{R}^{n \\times m}$, then the fitting vector $\\hat{X}^{(i)} \\in \\mathcal{R}^{n m}$. So we reshape accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "123cb6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(349, 4096)\n",
      "(62, 4096)\n"
     ]
    }
   ],
   "source": [
    "X_train_flat = X_train.reshape(X_train.shape[0], X_train.shape[1] * X_train.shape[2])\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], X_test.shape[1] * X_test.shape[2])\n",
    "print(X_train_flat.shape)\n",
    "print(X_test_flat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511f5ded",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c725fb6",
   "metadata": {},
   "source": [
    "We have 4096 pixels per observation, neatly stacked in a vector. All observations together (349 for train, 62 for test), gives us a (two-dimensional) matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3499d6fa",
   "metadata": {},
   "source": [
    "## 2. A neural network with an (arbitrarily large) hidden layer of neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f547f6",
   "metadata": {},
   "source": [
    "This time, we are creating a model that uses multiple neurons instead of just one. In particular, we will use one hidden layer with `hidden_layer_size` neurons (and the ReLU activation function), and an output layer with a single neuron performing the final binary classification (what activation function do we use here?)\n",
    "\n",
    "The principle approach is the same as before:\n",
    "\n",
    "0. Choose hyperparameters\n",
    "1. Initialize the model parameters $\\theta$ (random weights!)\n",
    "2. Until we cannot improve the cost function anymore (or we reach a certain numer of iterations):\n",
    "- Given your current model parameters, compute the cost function $J(\\theta)$ (forward propagation)\n",
    "- From the cost function, go backward to compute all the relevant derivatives (back-propagation)\n",
    "- Update the parameters: $\\theta := \\theta - \\alpha \\nabla_{\\theta} J(\\theta)$\n",
    "\n",
    "### Initialization\n",
    "\n",
    "Keep in mind that each neuron in the hidden layer has weights for all $m$ incoming edges (i.e. one for each `dimension`), as well as one bias term. The single neuron in the output layer has one weight for each of its incoming edges, as well as its own bias term.\n",
    "\n",
    "We will usually use dictionaries to store parameters when we have many. The function below is partially completed for you - can you finish it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa5972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(seed=392, dimension=4096, hidden_layer_size=3):\n",
    "    np.random.seed(seed)\n",
    "    parameters = {\n",
    "        \"weights1\": np.random.rand(dimension, hidden_layer_size)\n",
    "        * 0.01,  # Use np.random.rand(dim1,dim2)*0.01, inputing the correct dimensions\n",
    "        \"bias1\": np.zeros(\n",
    "            (1, hidden_layer_size)\n",
    "        ),  # Use np.zeros(shape), inputing the correct shape\n",
    "        \"weights2\": np.random.randn(hidden_layer_size, 1)\n",
    "        * 0.01,  # Use np.random.randn(dim1,dim2)*0.01, inputing the correct dimensions\n",
    "        \"bias2\": np.zeros((1, 1)),\n",
    "    }  # Use np.zeros(shape), inputing the correct shape\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6a5c8",
   "metadata": {},
   "source": [
    "A quick try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a8077456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 3)\n",
      "(1, 3)\n",
      "(3, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(seed=123,dimension=4096,hidden_layer_size=3)\n",
    "print(parameters[\"weights1\"].shape)\n",
    "print(parameters[\"bias1\"].shape)\n",
    "print(parameters[\"weights2\"].shape)\n",
    "print(parameters[\"bias2\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89236afc",
   "metadata": {},
   "source": [
    "### Forward propagation\n",
    "\n",
    "The forward propagation step is quite similar to what we saw in the logistic regression. Of course, our model for $\\hat{y}$ is now a whole lot more complex. But that doesn't matter: the neural network is essentially a computation graph, so we just go layer by layer, and computations are quite easy at each layer. We will make use of two helper functions to compute the ReLU activation (at the hidden layer) and the logistic sigmoid activation (at the output layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3df91205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0,z)     # for proper vectorization, you might want to look up `np.maximum`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d234fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(z):\n",
    "    return 1/(1 + np.exp(-z))  # you have seen this before in logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56e1684",
   "metadata": {},
   "source": [
    "Remember that we want to make fast computations. Hence, our functions need to be able to take a whole matrix of values and compute the activation for each element (they need to be \"vectorized\"). Try it out for both activation functions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f0c9806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 3]\n",
      " [0 6 0]\n",
      " [3 0 0]]\n",
      "[[0.73105858 0.11920292 0.95257413]\n",
      " [0.5        0.99752738 0.11920292]\n",
      " [0.95257413 0.26894142 0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "Z = np.array([[1,-2,3],\n",
    "              [0,6,-2],\n",
    "              [3,-1,0]])\n",
    "print(relu(Z))\n",
    "print(sigma(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa8c612",
   "metadata": {},
   "source": [
    "Next comes the actual forward propagation step. Remember that we need to compute:\n",
    "1. For each neuron at the first layer:\n",
    "- $Z^{[1]}$ = the weighted sum of the inputs X, to which we add the bias\n",
    "- $A^{[1]}$ = the actual activation: the neuron's activation function applied to $Z^{[1]}$\n",
    "2. For the neuron at the second layer:\n",
    "- $Z^{[2]}$ = the weighted sum of the inputs $A^{[1]}$, to which we add the bias\n",
    "- $A^{[2]}$ = the actual activation: the neuron's activation function applied to $Z^{[2]}$\n",
    "3. The cost function, given $\\hat{y} = A^{[2]}$: We will stick with what we saw before in binary classification, so $J=\\frac{1}{n}\\sum_{i=1}^n L^{(i)}$ with $L^{(i)} = -y^{(i)} \\log \\hat y^{(i)} - (1-y^{(i)}) (1-\\log \\hat y^{(i)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda3efc7",
   "metadata": {},
   "source": [
    "Aside from the cost, the forward propagation should return the computed Z's and A's in what we call a \"cache\". This is important for back-propagation later down the line.\n",
    "\n",
    "We start with a naive implementation, where we compute the activations for each neuron separately. Do you see what happens in the function below? Can you complete the missing pieces?\n",
    "\n",
    "A few hints:\n",
    "- you might benefit from adding print statements and trying out the function using `forward_propagation_naive(X_train_flat,y_train,parameters,2)`\n",
    "- The input matrix $X$ has dimensions $(n,m)$, where $n$ is the number of observations and $m$ the number of features\n",
    "- The weight matrix $W^{[1]}$ has dimensions $(m,\\text{hidden_layer_size})$\n",
    "- The bias vector $b^{[1]}$ has dimensions $(1,\\text{hidden_layer_size})$\n",
    "- The weight matrix $W^{[2]}$ has dimensions $(\\text{hidden_layer_size},1)$\n",
    "- The bias vector $b^{[2]}$ has dimensions $(1,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a273ead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation_naive(X,y,parameters,hidden_layer_size):\n",
    "    # Layer 1 (hidden layer)\n",
    "    Z1 = np.zeros((X.shape[0],hidden_layer_size))\n",
    "    A1 = np.zeros((X.shape[0],hidden_layer_size))\n",
    "    for neuron in range(hidden_layer_size):\n",
    "        w = parameters['weights1'][:,neuron] # find the right weight (recall that we stacked our weights with shape (in,out))\n",
    "        b = parameters['bias1'][0,neuron]    # find the right bias term (recall that we stacked our biases with shape (1,out))\n",
    "        z = np.dot(X,w) + b                  # compute z, using np.dot. Think of the correct dimensions!\n",
    "        Z1[:,neuron] = z\n",
    "        A1[:,neuron] = relu(z)\n",
    "    \n",
    "    # Layer 2 (output layer)\n",
    "    Z2 = np.dot(A1,parameters['weights2']) + parameters['bias2'] # at the second layer, there is only one node. Use np.dot again, and watch out for the correct dimensions\n",
    "    A2 = sigma(Z2)\n",
    "    \n",
    "    # Compute the cost\n",
    "    yHat = A2\n",
    "    cost = np.sum(-y*np.log(yHat) - (1-y)*np.log(1-yHat))/X.shape[0]\n",
    "    \n",
    "    # Compute the cache\n",
    "    cache = {'Z1': Z1,\n",
    "             'A1': A1,\n",
    "             'Z2': Z2,\n",
    "             'A2': A2}\n",
    "    \n",
    "    return cost, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c24b462",
   "metadata": {},
   "source": [
    "Try it out. If there are no mistake, the code below should print out 0.7387257645994343"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f49fd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7387257645994343\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(seed=123,dimension=4096,hidden_layer_size=3)\n",
    "cost, _ = forward_propagation_naive(X_train_flat,y_train,parameters,3)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb48a7e9",
   "metadata": {},
   "source": [
    "We know that vectorization is faster, so we will vectorize not just on the observations, but also on the neurons within a layer (and then see that this is quite a bit faster). Can you complete the function?\n",
    "\n",
    "A few additional hints here:\n",
    "- Each neuron has its own total input z for each observations. Hence, $Z^{[1]}$ should have dimensions $(n,\\text{hidden_layer_size})$\n",
    "- The same logic holds for the neuron at the second layer. Hence, $Z^{[2]}$ should have dimensions $(n,1)$\n",
    "- The activation matrix $A^{[l]}$ has the same dimensions as the total input matrix $Z^{[l]}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db6bc8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X,y,parameters):\n",
    "    # Layer 1 (hidden layer)\n",
    "    Z1 = np.dot(X,parameters['weights1']) + parameters['bias1']  # Use np.dot!\n",
    "    A1 = relu(Z1)\n",
    "    \n",
    "    # Layer 2 (output layer)\n",
    "    Z2 = np.dot(A1,parameters['weights2']) + parameters['bias2'] # Use np.dot!\n",
    "    A2 = sigma(Z2)\n",
    "    \n",
    "    # Compute the cost - this is exactly as before!\n",
    "    yHat = A2\n",
    "    cost = np.sum(-y*np.log(yHat) - (1-y)*np.log(1-yHat))/X.shape[0]\n",
    "    \n",
    "    # Compute the cache\n",
    "    cache = {'Z1': Z1,\n",
    "             'A1': A1,\n",
    "             'Z2': Z2,\n",
    "             'A2': A2}\n",
    "    \n",
    "    return cost, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb57dd",
   "metadata": {},
   "source": [
    "Try it out. If there are no mistake, the code below should print out\n",
    "1. 0.7387257645994343\n",
    "1. (349,3)\n",
    "1. (349,3)\n",
    "1. (349,1)\n",
    "1. (349,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87b180cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7387257645994345\n",
      "(349, 3)\n",
      "(349, 3)\n",
      "(349, 1)\n",
      "(349, 1)\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(seed=123,dimension=4096,hidden_layer_size=3)\n",
    "cost, cache = forward_propagation(X_train_flat,y_train,parameters)\n",
    "print(cost)\n",
    "print(cache['Z1'].shape)\n",
    "print(cache['A1'].shape)\n",
    "print(cache['Z2'].shape)\n",
    "print(cache['A2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80773e10",
   "metadata": {},
   "source": [
    "Let's now compare the difference in computation time. What we will do is to create 200 sets of initial parameters for a network of width 10 and apply forward propagation once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1538f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive: Cost = 0.7061321562751905, computation time = 154.50435500000012ms\n",
      "Vectorized: Cost = 0.7061321562751905, computation time = 26.139105000000107ms\n"
     ]
    }
   ],
   "source": [
    "iterations = 200\n",
    "time_naive = 0\n",
    "cost_naive = 0\n",
    "time_vectorized = 0\n",
    "cost_vectorized = 0\n",
    "\n",
    "for it in range(iterations):\n",
    "    parameters = initialize_parameters(seed=np.random.randint(1),dimension=4096,hidden_layer_size=10)\n",
    "    # Running things with a for-loop:\n",
    "    tic = time.process_time()\n",
    "    cost,_ = forward_propagation_naive(X_train_flat,y_train,parameters,10)\n",
    "    toc = time.process_time()\n",
    "    time_naive += 1000*(toc-tic)\n",
    "    cost_naive += cost\n",
    "    # Running things \"vectorized\":\n",
    "    tic = time.process_time()\n",
    "    cost,_ = forward_propagation(X_train_flat,y_train,parameters)\n",
    "    toc = time.process_time()\n",
    "    time_vectorized += 1000*(toc-tic)\n",
    "    cost_vectorized += cost\n",
    "\n",
    "print (\"Naive: Cost = \" + str(cost_naive/iterations) + \", computation time = \" + str(time_naive/iterations) + \"ms\")\n",
    "print (\"Vectorized: Cost = \" + str(cost_vectorized/iterations) + \", computation time = \" + str(time_vectorized/iterations) + \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f810c",
   "metadata": {},
   "source": [
    "### Back-propagation\n",
    "\n",
    "We move onto the second step of our update: finding the gradients. Make sure you use the chain rule. We will discuss in the tutorial how to derive the derivatives, but for the programming part, the relevant computations can be found below:\n",
    "- `dZ2` $= \\nabla_{Z^{[2]}} J = \\frac{1}{n}(A^{[2]} - y)$  (this should give you a $(n,1)$ matrix - why?)\n",
    "- `dW2` $=\\nabla_{W^{[2]}} J  = (A^{[1]})^T  (\\nabla_{Z^{[2]}} J)$ (this should give you a $(\\text{hidden_layer_size},1)$ matrix - why?)\n",
    "- `db2` $=\\nabla_{b^{[2]}} J = \\sum_{i=1}^n \\frac{\\partial J}{\\partial z_1^{[2](i)}}$ (you are summing up over the entries of dZ2)\n",
    "- `dZ1` $= \\nabla_{Z^{[1]}} J = (\\nabla_{Z^{[2]}} J) (W^{[2]})^T \\circ E^{[1]}$. Here, $\\circ$ is element-wise multiplication and $E^{[1]}$ is a matrix of the same dimensions as $Z^{[1]}$ that is 1 when the entry is positive and 0 otherwise (this should give you a $(n,\\text{hidden_layer_size})$ matrix - why?)\n",
    "- `dW1` $=\\nabla_{W^{[1]}} J  = (X^T)(\\nabla_{Z^{[1]}} J)$ (this should give you a $(m,\\text{hidden_layer_size})$ matrix - why?)\n",
    "- `db1` = $\\left[ \\nabla_{b^{[1]}_1} J, \\nabla_{b^{[1]}_2} J,..., \\nabla_{b^{[1]}_{\\text{hidden_layer_size}}} J \\right] = \\left[\\sum_{i=1}^n \\frac{\\partial J}{\\partial z_1^{[1](i)}}, \\sum_{i=1}^n \\frac{\\partial J}{\\partial z_2^{[1](i)}}, ..., \\sum_{i=1}^n \\frac{\\partial J}{\\partial z_{\\text{hidden_layer_size}}^{[1](i)}} \\right]$ (you are summing up over **one** of the axes of dZ1 - be careful to choose the right one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2b9a78",
   "metadata": {},
   "source": [
    "A final hint about computing $E^{[1]}$. See the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d83b4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.array([[1,-2,3],\n",
    "              [0,6,-2],\n",
    "              [3,-1,0]])\n",
    "np.where(Z>0,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76da48a9",
   "metadata": {},
   "source": [
    "We can now define the back-propagation step, which returns the gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ece447e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagation(X, y, parameters, cache):\n",
    "\n",
    "    dZ2 = (cache[\"A2\"] - y) / X.shape[0]\n",
    "    dW2 = np.dot(cache[\"A1\"].T, dZ2)\n",
    "    db2 = np.sum(dZ2, axis=0, keepdims=True)\n",
    "\n",
    "    dZ1 = np.dot(dZ2, parameters[\"weights2\"].T) * np.where(cache[\"Z1\"] > 0, 1, 0)\n",
    "    dW1 = np.dot(X.T, dZ1)\n",
    "    db1 = np.sum(\n",
    "        dZ1, axis=0, keepdims=True\n",
    "    )  # make sure to sum up over the right axis (see the np.sum documentation), and to set keepdims=True\n",
    "    grads = {\"weights1\": dW1, \"bias1\": db1, \"weights2\": dW2, \"bias2\": db2}\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23bfa61",
   "metadata": {},
   "source": [
    "If everything is programmed correctly, the below code should print out\n",
    "\n",
    "1. -0.000508086877680383\n",
    "1. (4096, 3)\n",
    "1. (1, 3)\n",
    "1. (3, 1)\n",
    "1. (1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d982a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0005080868776803828\n",
      "(4096, 3)\n",
      "(1, 3)\n",
      "(3, 1)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(seed=123,dimension=4096,hidden_layer_size=3)\n",
    "cost, cache = forward_propagation(X_train_flat,y_train,parameters)\n",
    "grads = back_propagation(X_train_flat,y_train,parameters,cache)\n",
    "print(grads['weights1'][0,0])\n",
    "print(grads['weights1'].shape)\n",
    "print(grads['bias1'].shape)\n",
    "print(grads['weights2'].shape)\n",
    "print(grads['bias2'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817938b",
   "metadata": {},
   "source": [
    "### Putting it together: parameter updating and training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4df55ce",
   "metadata": {},
   "source": [
    "In each iteration of our learning procedure, we update the parameters, hopefully moving closer towards the optimum. How we update the parameters is determined by the gradient, as well as the learning rate (a hyper-parameter). Let's define one update step:\n",
    "1. Compute the `forward_propagation` step (returning `cost` and `cache`)\n",
    "1. Compute the `back_propagation` step (using `cache` from `forward_propagation`)\n",
    "1. Update each entry in `parameters` as follows: $\\theta := \\theta - \\alpha \\nabla_{\\theta} J$ (Because we made sure above that the shapes are \"in the right way\", we don't have to worry about individual parameters, but can update whole groups - also, we made sure that the parameters and their gradients are referenced in the same way in both dictionaries. Note that $\\alpha$ is the learning rate)\n",
    "1. Return the updated dictionary `parameters` and the `cost` from `forward_propagation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0a82d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_update(X,y,parameters,learning_rate):\n",
    "    cost, cache = forward_propagation(X,y,parameters)\n",
    "    grads = back_propagation(X,y,parameters,cache)\n",
    "    for entry in parameters:\n",
    "        parameters[entry] = parameters[entry] - learning_rate*grads[entry]\n",
    "    return parameters, cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5141b4",
   "metadata": {},
   "source": [
    "We can now train our model, by running the parameter update multiple times. We will use 3 neurons at the hidden layer, a learning rate of 0.01 and run the algorithm for 2,500 iterations. Can you adjust the function below? Make sure to initialize the parameters with our custom-made function. Also, each time you run the parameter-update, store the resulting `cost` in a list `cost_list`. At the end, return the final `parameter` dictionary and the `cost_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbc2cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(X,y,hidden_layer_size=3,learning_rate=0.01,iterations=2500,verbose=True):\n",
    "    parameters = initialize_parameters(seed=np.random.randint(1),dimension=X.shape[1],hidden_layer_size=hidden_layer_size) # Initialize the parameters\n",
    "    cost_list = []\n",
    "    for it in range(iterations):\n",
    "        parameters,cost = parameter_update(X,y,parameters,learning_rate) # for each iteration, update the parameters using forward and back propagation\n",
    "        cost_list.append(cost)  # Also, make sure to add the cost to the cost_list\n",
    "        if verbose:\n",
    "            print('Cost after iteration %i: %f' %(it,cost))\n",
    "    return parameters, cost_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37873d5d",
   "metadata": {},
   "source": [
    "Now, train the model and display the training loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f91c093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39fdda19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693185\n",
      "Cost after iteration 1: 0.693181\n",
      "Cost after iteration 2: 0.693178\n",
      "Cost after iteration 3: 0.693175\n",
      "Cost after iteration 4: 0.693172\n",
      "Cost after iteration 5: 0.693169\n",
      "Cost after iteration 6: 0.693166\n",
      "Cost after iteration 7: 0.693162\n",
      "Cost after iteration 8: 0.693159\n",
      "Cost after iteration 9: 0.693156\n",
      "Cost after iteration 10: 0.693153\n",
      "Cost after iteration 11: 0.693150\n",
      "Cost after iteration 12: 0.693147\n",
      "Cost after iteration 13: 0.693144\n",
      "Cost after iteration 14: 0.693141\n",
      "Cost after iteration 15: 0.693138\n",
      "Cost after iteration 16: 0.693135\n",
      "Cost after iteration 17: 0.693132\n",
      "Cost after iteration 18: 0.693129\n",
      "Cost after iteration 19: 0.693127\n",
      "Cost after iteration 20: 0.693124\n",
      "Cost after iteration 21: 0.693121\n",
      "Cost after iteration 22: 0.693118\n",
      "Cost after iteration 23: 0.693115\n",
      "Cost after iteration 24: 0.693112\n",
      "Cost after iteration 25: 0.693108\n",
      "Cost after iteration 26: 0.693105\n",
      "Cost after iteration 27: 0.693102\n",
      "Cost after iteration 28: 0.693099\n",
      "Cost after iteration 29: 0.693096\n",
      "Cost after iteration 30: 0.693093\n",
      "Cost after iteration 31: 0.693090\n",
      "Cost after iteration 32: 0.693087\n",
      "Cost after iteration 33: 0.693084\n",
      "Cost after iteration 34: 0.693080\n",
      "Cost after iteration 35: 0.693077\n",
      "Cost after iteration 36: 0.693074\n",
      "Cost after iteration 37: 0.693071\n",
      "Cost after iteration 38: 0.693067\n",
      "Cost after iteration 39: 0.693064\n",
      "Cost after iteration 40: 0.693060\n",
      "Cost after iteration 41: 0.693057\n",
      "Cost after iteration 42: 0.693053\n",
      "Cost after iteration 43: 0.693050\n",
      "Cost after iteration 44: 0.693046\n",
      "Cost after iteration 45: 0.693043\n",
      "Cost after iteration 46: 0.693039\n",
      "Cost after iteration 47: 0.693035\n",
      "Cost after iteration 48: 0.693031\n",
      "Cost after iteration 49: 0.693028\n",
      "Cost after iteration 50: 0.693024\n",
      "Cost after iteration 51: 0.693020\n",
      "Cost after iteration 52: 0.693016\n",
      "Cost after iteration 53: 0.693012\n",
      "Cost after iteration 54: 0.693007\n",
      "Cost after iteration 55: 0.693003\n",
      "Cost after iteration 56: 0.692999\n",
      "Cost after iteration 57: 0.692995\n",
      "Cost after iteration 58: 0.692990\n",
      "Cost after iteration 59: 0.692986\n",
      "Cost after iteration 60: 0.692981\n",
      "Cost after iteration 61: 0.692976\n",
      "Cost after iteration 62: 0.692971\n",
      "Cost after iteration 63: 0.692967\n",
      "Cost after iteration 64: 0.692962\n",
      "Cost after iteration 65: 0.692956\n",
      "Cost after iteration 66: 0.692951\n",
      "Cost after iteration 67: 0.692946\n",
      "Cost after iteration 68: 0.692941\n",
      "Cost after iteration 69: 0.692935\n",
      "Cost after iteration 70: 0.692930\n",
      "Cost after iteration 71: 0.692924\n",
      "Cost after iteration 72: 0.692918\n",
      "Cost after iteration 73: 0.692912\n",
      "Cost after iteration 74: 0.692906\n",
      "Cost after iteration 75: 0.692900\n",
      "Cost after iteration 76: 0.692894\n",
      "Cost after iteration 77: 0.692887\n",
      "Cost after iteration 78: 0.692881\n",
      "Cost after iteration 79: 0.692874\n",
      "Cost after iteration 80: 0.692867\n",
      "Cost after iteration 81: 0.692860\n",
      "Cost after iteration 82: 0.692853\n",
      "Cost after iteration 83: 0.692846\n",
      "Cost after iteration 84: 0.692838\n",
      "Cost after iteration 85: 0.692830\n",
      "Cost after iteration 86: 0.692823\n",
      "Cost after iteration 87: 0.692815\n",
      "Cost after iteration 88: 0.692807\n",
      "Cost after iteration 89: 0.692798\n",
      "Cost after iteration 90: 0.692790\n",
      "Cost after iteration 91: 0.692781\n",
      "Cost after iteration 92: 0.692772\n",
      "Cost after iteration 93: 0.692763\n",
      "Cost after iteration 94: 0.692754\n",
      "Cost after iteration 95: 0.692744\n",
      "Cost after iteration 96: 0.692735\n",
      "Cost after iteration 97: 0.692725\n",
      "Cost after iteration 98: 0.692715\n",
      "Cost after iteration 99: 0.692704\n",
      "Cost after iteration 100: 0.692694\n",
      "Cost after iteration 101: 0.692683\n",
      "Cost after iteration 102: 0.692672\n",
      "Cost after iteration 103: 0.692660\n",
      "Cost after iteration 104: 0.692649\n",
      "Cost after iteration 105: 0.692637\n",
      "Cost after iteration 106: 0.692625\n",
      "Cost after iteration 107: 0.692612\n",
      "Cost after iteration 108: 0.692599\n",
      "Cost after iteration 109: 0.692586\n",
      "Cost after iteration 110: 0.692573\n",
      "Cost after iteration 111: 0.692559\n",
      "Cost after iteration 112: 0.692545\n",
      "Cost after iteration 113: 0.692531\n",
      "Cost after iteration 114: 0.692517\n",
      "Cost after iteration 115: 0.692502\n",
      "Cost after iteration 116: 0.692486\n",
      "Cost after iteration 117: 0.692471\n",
      "Cost after iteration 118: 0.692455\n",
      "Cost after iteration 119: 0.692438\n",
      "Cost after iteration 120: 0.692422\n",
      "Cost after iteration 121: 0.692405\n",
      "Cost after iteration 122: 0.692387\n",
      "Cost after iteration 123: 0.692369\n",
      "Cost after iteration 124: 0.692351\n",
      "Cost after iteration 125: 0.692332\n",
      "Cost after iteration 126: 0.692313\n",
      "Cost after iteration 127: 0.692293\n",
      "Cost after iteration 128: 0.692273\n",
      "Cost after iteration 129: 0.692252\n",
      "Cost after iteration 130: 0.692231\n",
      "Cost after iteration 131: 0.692210\n",
      "Cost after iteration 132: 0.692188\n",
      "Cost after iteration 133: 0.692165\n",
      "Cost after iteration 134: 0.692142\n",
      "Cost after iteration 135: 0.692118\n",
      "Cost after iteration 136: 0.692094\n",
      "Cost after iteration 137: 0.692069\n",
      "Cost after iteration 138: 0.692044\n",
      "Cost after iteration 139: 0.692018\n",
      "Cost after iteration 140: 0.691991\n",
      "Cost after iteration 141: 0.691964\n",
      "Cost after iteration 142: 0.691936\n",
      "Cost after iteration 143: 0.691908\n",
      "Cost after iteration 144: 0.691879\n",
      "Cost after iteration 145: 0.691849\n",
      "Cost after iteration 146: 0.691818\n",
      "Cost after iteration 147: 0.691787\n",
      "Cost after iteration 148: 0.691755\n",
      "Cost after iteration 149: 0.691722\n",
      "Cost after iteration 150: 0.691689\n",
      "Cost after iteration 151: 0.691655\n",
      "Cost after iteration 152: 0.691619\n",
      "Cost after iteration 153: 0.691584\n",
      "Cost after iteration 154: 0.691547\n",
      "Cost after iteration 155: 0.691509\n",
      "Cost after iteration 156: 0.691471\n",
      "Cost after iteration 157: 0.691431\n",
      "Cost after iteration 158: 0.691391\n",
      "Cost after iteration 159: 0.691350\n",
      "Cost after iteration 160: 0.691307\n",
      "Cost after iteration 161: 0.691264\n",
      "Cost after iteration 162: 0.691220\n",
      "Cost after iteration 163: 0.691175\n",
      "Cost after iteration 164: 0.691128\n",
      "Cost after iteration 165: 0.691081\n",
      "Cost after iteration 166: 0.691032\n",
      "Cost after iteration 167: 0.690983\n",
      "Cost after iteration 168: 0.690932\n",
      "Cost after iteration 169: 0.690880\n",
      "Cost after iteration 170: 0.690826\n",
      "Cost after iteration 171: 0.690772\n",
      "Cost after iteration 172: 0.690716\n",
      "Cost after iteration 173: 0.690659\n",
      "Cost after iteration 174: 0.690601\n",
      "Cost after iteration 175: 0.690541\n",
      "Cost after iteration 176: 0.690480\n",
      "Cost after iteration 177: 0.690417\n",
      "Cost after iteration 178: 0.690353\n",
      "Cost after iteration 179: 0.690287\n",
      "Cost after iteration 180: 0.690220\n",
      "Cost after iteration 181: 0.690151\n",
      "Cost after iteration 182: 0.690081\n",
      "Cost after iteration 183: 0.690009\n",
      "Cost after iteration 184: 0.689935\n",
      "Cost after iteration 185: 0.689860\n",
      "Cost after iteration 186: 0.689783\n",
      "Cost after iteration 187: 0.689704\n",
      "Cost after iteration 188: 0.689623\n",
      "Cost after iteration 189: 0.689541\n",
      "Cost after iteration 190: 0.689456\n",
      "Cost after iteration 191: 0.689370\n",
      "Cost after iteration 192: 0.689281\n",
      "Cost after iteration 193: 0.689190\n",
      "Cost after iteration 194: 0.689098\n",
      "Cost after iteration 195: 0.689003\n",
      "Cost after iteration 196: 0.688906\n",
      "Cost after iteration 197: 0.688806\n",
      "Cost after iteration 198: 0.688705\n",
      "Cost after iteration 199: 0.688601\n",
      "Cost after iteration 200: 0.688494\n",
      "Cost after iteration 201: 0.688385\n",
      "Cost after iteration 202: 0.688274\n",
      "Cost after iteration 203: 0.688160\n",
      "Cost after iteration 204: 0.688043\n",
      "Cost after iteration 205: 0.687924\n",
      "Cost after iteration 206: 0.687802\n",
      "Cost after iteration 207: 0.687677\n",
      "Cost after iteration 208: 0.687549\n",
      "Cost after iteration 209: 0.687418\n",
      "Cost after iteration 210: 0.687284\n",
      "Cost after iteration 211: 0.687147\n",
      "Cost after iteration 212: 0.687007\n",
      "Cost after iteration 213: 0.686864\n",
      "Cost after iteration 214: 0.686717\n",
      "Cost after iteration 215: 0.686567\n",
      "Cost after iteration 216: 0.686414\n",
      "Cost after iteration 217: 0.686257\n",
      "Cost after iteration 218: 0.686096\n",
      "Cost after iteration 219: 0.685932\n",
      "Cost after iteration 220: 0.685764\n",
      "Cost after iteration 221: 0.685592\n",
      "Cost after iteration 222: 0.685417\n",
      "Cost after iteration 223: 0.685237\n",
      "Cost after iteration 224: 0.685053\n",
      "Cost after iteration 225: 0.684865\n",
      "Cost after iteration 226: 0.684672\n",
      "Cost after iteration 227: 0.684475\n",
      "Cost after iteration 228: 0.684274\n",
      "Cost after iteration 229: 0.684068\n",
      "Cost after iteration 230: 0.683858\n",
      "Cost after iteration 231: 0.683642\n",
      "Cost after iteration 232: 0.683422\n",
      "Cost after iteration 233: 0.683197\n",
      "Cost after iteration 234: 0.682966\n",
      "Cost after iteration 235: 0.682731\n",
      "Cost after iteration 236: 0.682490\n",
      "Cost after iteration 237: 0.682244\n",
      "Cost after iteration 238: 0.681992\n",
      "Cost after iteration 239: 0.681734\n",
      "Cost after iteration 240: 0.681471\n",
      "Cost after iteration 241: 0.681202\n",
      "Cost after iteration 242: 0.680926\n",
      "Cost after iteration 243: 0.680645\n",
      "Cost after iteration 244: 0.680357\n",
      "Cost after iteration 245: 0.680063\n",
      "Cost after iteration 246: 0.679762\n",
      "Cost after iteration 247: 0.679455\n",
      "Cost after iteration 248: 0.679141\n",
      "Cost after iteration 249: 0.678819\n",
      "Cost after iteration 250: 0.678491\n",
      "Cost after iteration 251: 0.678155\n",
      "Cost after iteration 252: 0.677812\n",
      "Cost after iteration 253: 0.677462\n",
      "Cost after iteration 254: 0.677103\n",
      "Cost after iteration 255: 0.676737\n",
      "Cost after iteration 256: 0.676363\n",
      "Cost after iteration 257: 0.675980\n",
      "Cost after iteration 258: 0.675589\n",
      "Cost after iteration 259: 0.675190\n",
      "Cost after iteration 260: 0.674782\n",
      "Cost after iteration 261: 0.674365\n",
      "Cost after iteration 262: 0.673939\n",
      "Cost after iteration 263: 0.673504\n",
      "Cost after iteration 264: 0.673059\n",
      "Cost after iteration 265: 0.672605\n",
      "Cost after iteration 266: 0.672141\n",
      "Cost after iteration 267: 0.671667\n",
      "Cost after iteration 268: 0.671183\n",
      "Cost after iteration 269: 0.670688\n",
      "Cost after iteration 270: 0.670183\n",
      "Cost after iteration 271: 0.669668\n",
      "Cost after iteration 272: 0.669141\n",
      "Cost after iteration 273: 0.668603\n",
      "Cost after iteration 274: 0.668054\n",
      "Cost after iteration 275: 0.667494\n",
      "Cost after iteration 276: 0.666921\n",
      "Cost after iteration 277: 0.666337\n",
      "Cost after iteration 278: 0.665741\n",
      "Cost after iteration 279: 0.665132\n",
      "Cost after iteration 280: 0.664511\n",
      "Cost after iteration 281: 0.663876\n",
      "Cost after iteration 282: 0.663229\n",
      "Cost after iteration 283: 0.662569\n",
      "Cost after iteration 284: 0.661895\n",
      "Cost after iteration 285: 0.661207\n",
      "Cost after iteration 286: 0.660505\n",
      "Cost after iteration 287: 0.659790\n",
      "Cost after iteration 288: 0.659060\n",
      "Cost after iteration 289: 0.658315\n",
      "Cost after iteration 290: 0.657555\n",
      "Cost after iteration 291: 0.656781\n",
      "Cost after iteration 292: 0.655991\n",
      "Cost after iteration 293: 0.655185\n",
      "Cost after iteration 294: 0.654364\n",
      "Cost after iteration 295: 0.653527\n",
      "Cost after iteration 296: 0.652673\n",
      "Cost after iteration 297: 0.651803\n",
      "Cost after iteration 298: 0.650916\n",
      "Cost after iteration 299: 0.650013\n",
      "Cost after iteration 300: 0.649092\n",
      "Cost after iteration 301: 0.648153\n",
      "Cost after iteration 302: 0.647197\n",
      "Cost after iteration 303: 0.646224\n",
      "Cost after iteration 304: 0.645232\n",
      "Cost after iteration 305: 0.644222\n",
      "Cost after iteration 306: 0.643193\n",
      "Cost after iteration 307: 0.642145\n",
      "Cost after iteration 308: 0.641079\n",
      "Cost after iteration 309: 0.639993\n",
      "Cost after iteration 310: 0.638887\n",
      "Cost after iteration 311: 0.637763\n",
      "Cost after iteration 312: 0.636618\n",
      "Cost after iteration 313: 0.635453\n",
      "Cost after iteration 314: 0.634268\n",
      "Cost after iteration 315: 0.633063\n",
      "Cost after iteration 316: 0.631836\n",
      "Cost after iteration 317: 0.630589\n",
      "Cost after iteration 318: 0.629321\n",
      "Cost after iteration 319: 0.628032\n",
      "Cost after iteration 320: 0.626722\n",
      "Cost after iteration 321: 0.625390\n",
      "Cost after iteration 322: 0.624036\n",
      "Cost after iteration 323: 0.622661\n",
      "Cost after iteration 324: 0.621263\n",
      "Cost after iteration 325: 0.619844\n",
      "Cost after iteration 326: 0.618402\n",
      "Cost after iteration 327: 0.616938\n",
      "Cost after iteration 328: 0.615452\n",
      "Cost after iteration 329: 0.613943\n",
      "Cost after iteration 330: 0.612411\n",
      "Cost after iteration 331: 0.610857\n",
      "Cost after iteration 332: 0.609280\n",
      "Cost after iteration 333: 0.607680\n",
      "Cost after iteration 334: 0.606058\n",
      "Cost after iteration 335: 0.604412\n",
      "Cost after iteration 336: 0.602744\n",
      "Cost after iteration 337: 0.601053\n",
      "Cost after iteration 338: 0.599339\n",
      "Cost after iteration 339: 0.597602\n",
      "Cost after iteration 340: 0.595842\n",
      "Cost after iteration 341: 0.594059\n",
      "Cost after iteration 342: 0.592254\n",
      "Cost after iteration 343: 0.590426\n",
      "Cost after iteration 344: 0.588576\n",
      "Cost after iteration 345: 0.586703\n",
      "Cost after iteration 346: 0.584808\n",
      "Cost after iteration 347: 0.582891\n",
      "Cost after iteration 348: 0.580951\n",
      "Cost after iteration 349: 0.578990\n",
      "Cost after iteration 350: 0.577007\n",
      "Cost after iteration 351: 0.575003\n",
      "Cost after iteration 352: 0.572977\n",
      "Cost after iteration 353: 0.570930\n",
      "Cost after iteration 354: 0.568863\n",
      "Cost after iteration 355: 0.566775\n",
      "Cost after iteration 356: 0.564666\n",
      "Cost after iteration 357: 0.562538\n",
      "Cost after iteration 358: 0.560390\n",
      "Cost after iteration 359: 0.558223\n",
      "Cost after iteration 360: 0.556037\n",
      "Cost after iteration 361: 0.553832\n",
      "Cost after iteration 362: 0.551609\n",
      "Cost after iteration 363: 0.549368\n",
      "Cost after iteration 364: 0.547109\n",
      "Cost after iteration 365: 0.544834\n",
      "Cost after iteration 366: 0.542542\n",
      "Cost after iteration 367: 0.540234\n",
      "Cost after iteration 368: 0.537910\n",
      "Cost after iteration 369: 0.535570\n",
      "Cost after iteration 370: 0.533216\n",
      "Cost after iteration 371: 0.530848\n",
      "Cost after iteration 372: 0.528466\n",
      "Cost after iteration 373: 0.526071\n",
      "Cost after iteration 374: 0.523663\n",
      "Cost after iteration 375: 0.521243\n",
      "Cost after iteration 376: 0.518811\n",
      "Cost after iteration 377: 0.516368\n",
      "Cost after iteration 378: 0.513915\n",
      "Cost after iteration 379: 0.511452\n",
      "Cost after iteration 380: 0.508979\n",
      "Cost after iteration 381: 0.506498\n",
      "Cost after iteration 382: 0.504008\n",
      "Cost after iteration 383: 0.501511\n",
      "Cost after iteration 384: 0.499007\n",
      "Cost after iteration 385: 0.496496\n",
      "Cost after iteration 386: 0.493980\n",
      "Cost after iteration 387: 0.491459\n",
      "Cost after iteration 388: 0.488932\n",
      "Cost after iteration 389: 0.486402\n",
      "Cost after iteration 390: 0.483869\n",
      "Cost after iteration 391: 0.481333\n",
      "Cost after iteration 392: 0.478794\n",
      "Cost after iteration 393: 0.476254\n",
      "Cost after iteration 394: 0.473713\n",
      "Cost after iteration 395: 0.471172\n",
      "Cost after iteration 396: 0.468631\n",
      "Cost after iteration 397: 0.466090\n",
      "Cost after iteration 398: 0.463551\n",
      "Cost after iteration 399: 0.461014\n",
      "Cost after iteration 400: 0.458479\n",
      "Cost after iteration 401: 0.455948\n",
      "Cost after iteration 402: 0.453419\n",
      "Cost after iteration 403: 0.450895\n",
      "Cost after iteration 404: 0.448376\n",
      "Cost after iteration 405: 0.445862\n",
      "Cost after iteration 406: 0.443353\n",
      "Cost after iteration 407: 0.440850\n",
      "Cost after iteration 408: 0.438354\n",
      "Cost after iteration 409: 0.435865\n",
      "Cost after iteration 410: 0.433384\n",
      "Cost after iteration 411: 0.430911\n",
      "Cost after iteration 412: 0.428446\n",
      "Cost after iteration 413: 0.425989\n",
      "Cost after iteration 414: 0.423542\n",
      "Cost after iteration 415: 0.421105\n",
      "Cost after iteration 416: 0.418678\n",
      "Cost after iteration 417: 0.416260\n",
      "Cost after iteration 418: 0.413854\n",
      "Cost after iteration 419: 0.411459\n",
      "Cost after iteration 420: 0.409075\n",
      "Cost after iteration 421: 0.406703\n",
      "Cost after iteration 422: 0.404343\n",
      "Cost after iteration 423: 0.401995\n",
      "Cost after iteration 424: 0.399659\n",
      "Cost after iteration 425: 0.397337\n",
      "Cost after iteration 426: 0.395027\n",
      "Cost after iteration 427: 0.392731\n",
      "Cost after iteration 428: 0.390448\n",
      "Cost after iteration 429: 0.388179\n",
      "Cost after iteration 430: 0.385924\n",
      "Cost after iteration 431: 0.383683\n",
      "Cost after iteration 432: 0.381456\n",
      "Cost after iteration 433: 0.379244\n",
      "Cost after iteration 434: 0.377046\n",
      "Cost after iteration 435: 0.374863\n",
      "Cost after iteration 436: 0.372695\n",
      "Cost after iteration 437: 0.370542\n",
      "Cost after iteration 438: 0.368404\n",
      "Cost after iteration 439: 0.366282\n",
      "Cost after iteration 440: 0.364176\n",
      "Cost after iteration 441: 0.362090\n",
      "Cost after iteration 442: 0.360032\n",
      "Cost after iteration 443: 0.358026\n",
      "Cost after iteration 444: 0.356147\n",
      "Cost after iteration 445: 0.354611\n",
      "Cost after iteration 446: 0.354076\n",
      "Cost after iteration 447: 0.356485\n",
      "Cost after iteration 448: 0.367669\n",
      "Cost after iteration 449: 0.403660\n",
      "Cost after iteration 450: 0.505755\n",
      "Cost after iteration 451: 0.724155\n",
      "Cost after iteration 452: 1.021288\n",
      "Cost after iteration 453: 1.075138\n",
      "Cost after iteration 454: 1.066030\n",
      "Cost after iteration 455: 0.963081\n",
      "Cost after iteration 456: 0.951102\n",
      "Cost after iteration 457: 0.866625\n",
      "Cost after iteration 458: 0.851436\n",
      "Cost after iteration 459: 0.782024\n",
      "Cost after iteration 460: 0.765573\n",
      "Cost after iteration 461: 0.708690\n",
      "Cost after iteration 462: 0.692243\n",
      "Cost after iteration 463: 0.645785\n",
      "Cost after iteration 464: 0.630140\n",
      "Cost after iteration 465: 0.592312\n",
      "Cost after iteration 466: 0.577932\n",
      "Cost after iteration 467: 0.547194\n",
      "Cost after iteration 468: 0.534300\n",
      "Cost after iteration 469: 0.509336\n",
      "Cost after iteration 470: 0.497980\n",
      "Cost after iteration 471: 0.477683\n",
      "Cost after iteration 472: 0.467804\n",
      "Cost after iteration 473: 0.451256\n",
      "Cost after iteration 474: 0.442731\n",
      "Cost after iteration 475: 0.429178\n",
      "Cost after iteration 476: 0.421854\n",
      "Cost after iteration 477: 0.410687\n",
      "Cost after iteration 478: 0.404402\n",
      "Cost after iteration 479: 0.395133\n",
      "Cost after iteration 480: 0.389735\n",
      "Cost after iteration 481: 0.381978\n",
      "Cost after iteration 482: 0.377327\n",
      "Cost after iteration 483: 0.370775\n",
      "Cost after iteration 484: 0.366752\n",
      "Cost after iteration 485: 0.361166\n",
      "Cost after iteration 486: 0.357668\n",
      "Cost after iteration 487: 0.352860\n",
      "Cost after iteration 488: 0.349803\n",
      "Cost after iteration 489: 0.345626\n",
      "Cost after iteration 490: 0.342940\n",
      "Cost after iteration 491: 0.339279\n",
      "Cost after iteration 492: 0.336907\n",
      "Cost after iteration 493: 0.333671\n",
      "Cost after iteration 494: 0.331568\n",
      "Cost after iteration 495: 0.328687\n",
      "Cost after iteration 496: 0.326816\n",
      "Cost after iteration 497: 0.324232\n",
      "Cost after iteration 498: 0.322564\n",
      "Cost after iteration 499: 0.320233\n",
      "Cost after iteration 500: 0.318742\n",
      "Cost after iteration 501: 0.316628\n",
      "Cost after iteration 502: 0.315296\n",
      "Cost after iteration 503: 0.313368\n",
      "Cost after iteration 504: 0.312177\n",
      "Cost after iteration 505: 0.310412\n",
      "Cost after iteration 506: 0.309349\n",
      "Cost after iteration 507: 0.307725\n",
      "Cost after iteration 508: 0.306776\n",
      "Cost after iteration 509: 0.305276\n",
      "Cost after iteration 510: 0.304429\n",
      "Cost after iteration 511: 0.303037\n",
      "Cost after iteration 512: 0.302281\n",
      "Cost after iteration 513: 0.300981\n",
      "Cost after iteration 514: 0.300304\n",
      "Cost after iteration 515: 0.299081\n",
      "Cost after iteration 516: 0.298472\n",
      "Cost after iteration 517: 0.297313\n",
      "Cost after iteration 518: 0.296759\n",
      "Cost after iteration 519: 0.295649\n",
      "Cost after iteration 520: 0.295136\n",
      "Cost after iteration 521: 0.294061\n",
      "Cost after iteration 522: 0.293576\n",
      "Cost after iteration 523: 0.292523\n",
      "Cost after iteration 524: 0.292050\n",
      "Cost after iteration 525: 0.291004\n",
      "Cost after iteration 526: 0.290529\n",
      "Cost after iteration 527: 0.289476\n",
      "Cost after iteration 528: 0.288982\n",
      "Cost after iteration 529: 0.287911\n",
      "Cost after iteration 530: 0.287384\n",
      "Cost after iteration 531: 0.286280\n",
      "Cost after iteration 532: 0.285705\n",
      "Cost after iteration 533: 0.284560\n",
      "Cost after iteration 534: 0.283924\n",
      "Cost after iteration 535: 0.282729\n",
      "Cost after iteration 536: 0.282019\n",
      "Cost after iteration 537: 0.280766\n",
      "Cost after iteration 538: 0.279975\n",
      "Cost after iteration 539: 0.278660\n",
      "Cost after iteration 540: 0.277779\n",
      "Cost after iteration 541: 0.276400\n",
      "Cost after iteration 542: 0.275426\n",
      "Cost after iteration 543: 0.273984\n",
      "Cost after iteration 544: 0.272914\n",
      "Cost after iteration 545: 0.271411\n",
      "Cost after iteration 546: 0.270248\n",
      "Cost after iteration 547: 0.268689\n",
      "Cost after iteration 548: 0.267436\n",
      "Cost after iteration 549: 0.265827\n",
      "Cost after iteration 550: 0.264491\n",
      "Cost after iteration 551: 0.262841\n",
      "Cost after iteration 552: 0.261430\n",
      "Cost after iteration 553: 0.259747\n",
      "Cost after iteration 554: 0.258272\n",
      "Cost after iteration 555: 0.256566\n",
      "Cost after iteration 556: 0.255038\n",
      "Cost after iteration 557: 0.253318\n",
      "Cost after iteration 558: 0.251748\n",
      "Cost after iteration 559: 0.250025\n",
      "Cost after iteration 560: 0.248426\n",
      "Cost after iteration 561: 0.246708\n",
      "Cost after iteration 562: 0.245092\n",
      "Cost after iteration 563: 0.243389\n",
      "Cost after iteration 564: 0.241767\n",
      "Cost after iteration 565: 0.240086\n",
      "Cost after iteration 566: 0.238469\n",
      "Cost after iteration 567: 0.236817\n",
      "Cost after iteration 568: 0.235215\n",
      "Cost after iteration 569: 0.233598\n",
      "Cost after iteration 570: 0.232019\n",
      "Cost after iteration 571: 0.230442\n",
      "Cost after iteration 572: 0.228893\n",
      "Cost after iteration 573: 0.227361\n",
      "Cost after iteration 574: 0.225848\n",
      "Cost after iteration 575: 0.224362\n",
      "Cost after iteration 576: 0.222891\n",
      "Cost after iteration 577: 0.221455\n",
      "Cost after iteration 578: 0.220028\n",
      "Cost after iteration 579: 0.218642\n",
      "Cost after iteration 580: 0.217262\n",
      "Cost after iteration 581: 0.215928\n",
      "Cost after iteration 582: 0.214596\n",
      "Cost after iteration 583: 0.213313\n",
      "Cost after iteration 584: 0.212031\n",
      "Cost after iteration 585: 0.210798\n",
      "Cost after iteration 586: 0.209565\n",
      "Cost after iteration 587: 0.208381\n",
      "Cost after iteration 588: 0.207198\n",
      "Cost after iteration 589: 0.206062\n",
      "Cost after iteration 590: 0.204927\n",
      "Cost after iteration 591: 0.203836\n",
      "Cost after iteration 592: 0.202747\n",
      "Cost after iteration 593: 0.201702\n",
      "Cost after iteration 594: 0.200657\n",
      "Cost after iteration 595: 0.199654\n",
      "Cost after iteration 596: 0.198653\n",
      "Cost after iteration 597: 0.197689\n",
      "Cost after iteration 598: 0.196729\n",
      "Cost after iteration 599: 0.195803\n",
      "Cost after iteration 600: 0.194881\n",
      "Cost after iteration 601: 0.193992\n",
      "Cost after iteration 602: 0.193107\n",
      "Cost after iteration 603: 0.192251\n",
      "Cost after iteration 604: 0.191400\n",
      "Cost after iteration 605: 0.190576\n",
      "Cost after iteration 606: 0.189757\n",
      "Cost after iteration 607: 0.188963\n",
      "Cost after iteration 608: 0.188175\n",
      "Cost after iteration 609: 0.187409\n",
      "Cost after iteration 610: 0.186649\n",
      "Cost after iteration 611: 0.185909\n",
      "Cost after iteration 612: 0.185175\n",
      "Cost after iteration 613: 0.184460\n",
      "Cost after iteration 614: 0.183751\n",
      "Cost after iteration 615: 0.183058\n",
      "Cost after iteration 616: 0.182372\n",
      "Cost after iteration 617: 0.181701\n",
      "Cost after iteration 618: 0.181036\n",
      "Cost after iteration 619: 0.180384\n",
      "Cost after iteration 620: 0.179740\n",
      "Cost after iteration 621: 0.179107\n",
      "Cost after iteration 622: 0.178480\n",
      "Cost after iteration 623: 0.177865\n",
      "Cost after iteration 624: 0.177256\n",
      "Cost after iteration 625: 0.176657\n",
      "Cost after iteration 626: 0.176064\n",
      "Cost after iteration 627: 0.175480\n",
      "Cost after iteration 628: 0.174902\n",
      "Cost after iteration 629: 0.174332\n",
      "Cost after iteration 630: 0.173768\n",
      "Cost after iteration 631: 0.173211\n",
      "Cost after iteration 632: 0.172660\n",
      "Cost after iteration 633: 0.172116\n",
      "Cost after iteration 634: 0.171577\n",
      "Cost after iteration 635: 0.171045\n",
      "Cost after iteration 636: 0.170517\n",
      "Cost after iteration 637: 0.169995\n",
      "Cost after iteration 638: 0.169478\n",
      "Cost after iteration 639: 0.168967\n",
      "Cost after iteration 640: 0.168460\n",
      "Cost after iteration 641: 0.167958\n",
      "Cost after iteration 642: 0.167461\n",
      "Cost after iteration 643: 0.166968\n",
      "Cost after iteration 644: 0.166480\n",
      "Cost after iteration 645: 0.165996\n",
      "Cost after iteration 646: 0.165516\n",
      "Cost after iteration 647: 0.165040\n",
      "Cost after iteration 648: 0.164567\n",
      "Cost after iteration 649: 0.164099\n",
      "Cost after iteration 650: 0.163634\n",
      "Cost after iteration 651: 0.163173\n",
      "Cost after iteration 652: 0.162716\n",
      "Cost after iteration 653: 0.162262\n",
      "Cost after iteration 654: 0.161811\n",
      "Cost after iteration 655: 0.161364\n",
      "Cost after iteration 656: 0.160919\n",
      "Cost after iteration 657: 0.160478\n",
      "Cost after iteration 658: 0.160041\n",
      "Cost after iteration 659: 0.159606\n",
      "Cost after iteration 660: 0.159174\n",
      "Cost after iteration 661: 0.158745\n",
      "Cost after iteration 662: 0.158319\n",
      "Cost after iteration 663: 0.157895\n",
      "Cost after iteration 664: 0.157475\n",
      "Cost after iteration 665: 0.157057\n",
      "Cost after iteration 666: 0.156642\n",
      "Cost after iteration 667: 0.156229\n",
      "Cost after iteration 668: 0.155819\n",
      "Cost after iteration 669: 0.155412\n",
      "Cost after iteration 670: 0.155007\n",
      "Cost after iteration 671: 0.154605\n",
      "Cost after iteration 672: 0.154205\n",
      "Cost after iteration 673: 0.153807\n",
      "Cost after iteration 674: 0.153412\n",
      "Cost after iteration 675: 0.153020\n",
      "Cost after iteration 676: 0.152629\n",
      "Cost after iteration 677: 0.152241\n",
      "Cost after iteration 678: 0.151855\n",
      "Cost after iteration 679: 0.151472\n",
      "Cost after iteration 680: 0.151091\n",
      "Cost after iteration 681: 0.150712\n",
      "Cost after iteration 682: 0.150335\n",
      "Cost after iteration 683: 0.149960\n",
      "Cost after iteration 684: 0.149588\n",
      "Cost after iteration 685: 0.149217\n",
      "Cost after iteration 686: 0.148849\n",
      "Cost after iteration 687: 0.148483\n",
      "Cost after iteration 688: 0.148119\n",
      "Cost after iteration 689: 0.147757\n",
      "Cost after iteration 690: 0.147397\n",
      "Cost after iteration 691: 0.147039\n",
      "Cost after iteration 692: 0.146683\n",
      "Cost after iteration 693: 0.146329\n",
      "Cost after iteration 694: 0.145977\n",
      "Cost after iteration 695: 0.145626\n",
      "Cost after iteration 696: 0.145278\n",
      "Cost after iteration 697: 0.144932\n",
      "Cost after iteration 698: 0.144588\n",
      "Cost after iteration 699: 0.144245\n",
      "Cost after iteration 700: 0.143905\n",
      "Cost after iteration 701: 0.143566\n",
      "Cost after iteration 702: 0.143229\n",
      "Cost after iteration 703: 0.142894\n",
      "Cost after iteration 704: 0.142560\n",
      "Cost after iteration 705: 0.142229\n",
      "Cost after iteration 706: 0.141899\n",
      "Cost after iteration 707: 0.141571\n",
      "Cost after iteration 708: 0.141245\n",
      "Cost after iteration 709: 0.140921\n",
      "Cost after iteration 710: 0.140598\n",
      "Cost after iteration 711: 0.140277\n",
      "Cost after iteration 712: 0.139957\n",
      "Cost after iteration 713: 0.139640\n",
      "Cost after iteration 714: 0.139324\n",
      "Cost after iteration 715: 0.139009\n",
      "Cost after iteration 716: 0.138697\n",
      "Cost after iteration 717: 0.138386\n",
      "Cost after iteration 718: 0.138076\n",
      "Cost after iteration 719: 0.137768\n",
      "Cost after iteration 720: 0.137462\n",
      "Cost after iteration 721: 0.137157\n",
      "Cost after iteration 722: 0.136854\n",
      "Cost after iteration 723: 0.136553\n",
      "Cost after iteration 724: 0.136253\n",
      "Cost after iteration 725: 0.135954\n",
      "Cost after iteration 726: 0.135657\n",
      "Cost after iteration 727: 0.135362\n",
      "Cost after iteration 728: 0.135068\n",
      "Cost after iteration 729: 0.134775\n",
      "Cost after iteration 730: 0.134484\n",
      "Cost after iteration 731: 0.134195\n",
      "Cost after iteration 732: 0.133906\n",
      "Cost after iteration 733: 0.133620\n",
      "Cost after iteration 734: 0.133335\n",
      "Cost after iteration 735: 0.133051\n",
      "Cost after iteration 736: 0.132768\n",
      "Cost after iteration 737: 0.132487\n",
      "Cost after iteration 738: 0.132208\n",
      "Cost after iteration 739: 0.131929\n",
      "Cost after iteration 740: 0.131652\n",
      "Cost after iteration 741: 0.131377\n",
      "Cost after iteration 742: 0.131103\n",
      "Cost after iteration 743: 0.130830\n",
      "Cost after iteration 744: 0.130558\n",
      "Cost after iteration 745: 0.130288\n",
      "Cost after iteration 746: 0.130019\n",
      "Cost after iteration 747: 0.129751\n",
      "Cost after iteration 748: 0.129485\n",
      "Cost after iteration 749: 0.129220\n",
      "Cost after iteration 750: 0.128956\n",
      "Cost after iteration 751: 0.128693\n",
      "Cost after iteration 752: 0.128432\n",
      "Cost after iteration 753: 0.128172\n",
      "Cost after iteration 754: 0.127913\n",
      "Cost after iteration 755: 0.127655\n",
      "Cost after iteration 756: 0.127399\n",
      "Cost after iteration 757: 0.127144\n",
      "Cost after iteration 758: 0.126890\n",
      "Cost after iteration 759: 0.126637\n",
      "Cost after iteration 760: 0.126385\n",
      "Cost after iteration 761: 0.126134\n",
      "Cost after iteration 762: 0.125885\n",
      "Cost after iteration 763: 0.125637\n",
      "Cost after iteration 764: 0.125390\n",
      "Cost after iteration 765: 0.125144\n",
      "Cost after iteration 766: 0.124899\n",
      "Cost after iteration 767: 0.124655\n",
      "Cost after iteration 768: 0.124412\n",
      "Cost after iteration 769: 0.124171\n",
      "Cost after iteration 770: 0.123930\n",
      "Cost after iteration 771: 0.123691\n",
      "Cost after iteration 772: 0.123453\n",
      "Cost after iteration 773: 0.123215\n",
      "Cost after iteration 774: 0.122979\n",
      "Cost after iteration 775: 0.122744\n",
      "Cost after iteration 776: 0.122510\n",
      "Cost after iteration 777: 0.122277\n",
      "Cost after iteration 778: 0.122045\n",
      "Cost after iteration 779: 0.121814\n",
      "Cost after iteration 780: 0.121584\n",
      "Cost after iteration 781: 0.121355\n",
      "Cost after iteration 782: 0.121127\n",
      "Cost after iteration 783: 0.120900\n",
      "Cost after iteration 784: 0.120674\n",
      "Cost after iteration 785: 0.120449\n",
      "Cost after iteration 786: 0.120225\n",
      "Cost after iteration 787: 0.120001\n",
      "Cost after iteration 788: 0.119779\n",
      "Cost after iteration 789: 0.119558\n",
      "Cost after iteration 790: 0.119338\n",
      "Cost after iteration 791: 0.119118\n",
      "Cost after iteration 792: 0.118900\n",
      "Cost after iteration 793: 0.118682\n",
      "Cost after iteration 794: 0.118466\n",
      "Cost after iteration 795: 0.118250\n",
      "Cost after iteration 796: 0.118035\n",
      "Cost after iteration 797: 0.117822\n",
      "Cost after iteration 798: 0.117609\n",
      "Cost after iteration 799: 0.117396\n",
      "Cost after iteration 800: 0.117185\n",
      "Cost after iteration 801: 0.116975\n",
      "Cost after iteration 802: 0.116765\n",
      "Cost after iteration 803: 0.116557\n",
      "Cost after iteration 804: 0.116349\n",
      "Cost after iteration 805: 0.116142\n",
      "Cost after iteration 806: 0.115936\n",
      "Cost after iteration 807: 0.115731\n",
      "Cost after iteration 808: 0.115526\n",
      "Cost after iteration 809: 0.115323\n",
      "Cost after iteration 810: 0.115120\n",
      "Cost after iteration 811: 0.114918\n",
      "Cost after iteration 812: 0.114717\n",
      "Cost after iteration 813: 0.114516\n",
      "Cost after iteration 814: 0.114317\n",
      "Cost after iteration 815: 0.114118\n",
      "Cost after iteration 816: 0.113920\n",
      "Cost after iteration 817: 0.113723\n",
      "Cost after iteration 818: 0.113526\n",
      "Cost after iteration 819: 0.113330\n",
      "Cost after iteration 820: 0.113136\n",
      "Cost after iteration 821: 0.112941\n",
      "Cost after iteration 822: 0.112748\n",
      "Cost after iteration 823: 0.112555\n",
      "Cost after iteration 824: 0.112363\n",
      "Cost after iteration 825: 0.112172\n",
      "Cost after iteration 826: 0.111982\n",
      "Cost after iteration 827: 0.111792\n",
      "Cost after iteration 828: 0.111603\n",
      "Cost after iteration 829: 0.111415\n",
      "Cost after iteration 830: 0.111227\n",
      "Cost after iteration 831: 0.111040\n",
      "Cost after iteration 832: 0.110854\n",
      "Cost after iteration 833: 0.110669\n",
      "Cost after iteration 834: 0.110484\n",
      "Cost after iteration 835: 0.110300\n",
      "Cost after iteration 836: 0.110117\n",
      "Cost after iteration 837: 0.109934\n",
      "Cost after iteration 838: 0.109752\n",
      "Cost after iteration 839: 0.109571\n",
      "Cost after iteration 840: 0.109390\n",
      "Cost after iteration 841: 0.109210\n",
      "Cost after iteration 842: 0.109031\n",
      "Cost after iteration 843: 0.108852\n",
      "Cost after iteration 844: 0.108674\n",
      "Cost after iteration 845: 0.108496\n",
      "Cost after iteration 846: 0.108320\n",
      "Cost after iteration 847: 0.108144\n",
      "Cost after iteration 848: 0.107968\n",
      "Cost after iteration 849: 0.107793\n",
      "Cost after iteration 850: 0.107619\n",
      "Cost after iteration 851: 0.107445\n",
      "Cost after iteration 852: 0.107272\n",
      "Cost after iteration 853: 0.107100\n",
      "Cost after iteration 854: 0.106928\n",
      "Cost after iteration 855: 0.106757\n",
      "Cost after iteration 856: 0.106587\n",
      "Cost after iteration 857: 0.106417\n",
      "Cost after iteration 858: 0.106247\n",
      "Cost after iteration 859: 0.106078\n",
      "Cost after iteration 860: 0.105910\n",
      "Cost after iteration 861: 0.105743\n",
      "Cost after iteration 862: 0.105576\n",
      "Cost after iteration 863: 0.105409\n",
      "Cost after iteration 864: 0.105243\n",
      "Cost after iteration 865: 0.105078\n",
      "Cost after iteration 866: 0.104913\n",
      "Cost after iteration 867: 0.104749\n",
      "Cost after iteration 868: 0.104585\n",
      "Cost after iteration 869: 0.104422\n",
      "Cost after iteration 870: 0.104260\n",
      "Cost after iteration 871: 0.104098\n",
      "Cost after iteration 872: 0.103936\n",
      "Cost after iteration 873: 0.103776\n",
      "Cost after iteration 874: 0.103615\n",
      "Cost after iteration 875: 0.103455\n",
      "Cost after iteration 876: 0.103296\n",
      "Cost after iteration 877: 0.103137\n",
      "Cost after iteration 878: 0.102979\n",
      "Cost after iteration 879: 0.102821\n",
      "Cost after iteration 880: 0.102664\n",
      "Cost after iteration 881: 0.102508\n",
      "Cost after iteration 882: 0.102351\n",
      "Cost after iteration 883: 0.102196\n",
      "Cost after iteration 884: 0.102041\n",
      "Cost after iteration 885: 0.101886\n",
      "Cost after iteration 886: 0.101732\n",
      "Cost after iteration 887: 0.101578\n",
      "Cost after iteration 888: 0.101425\n",
      "Cost after iteration 889: 0.101272\n",
      "Cost after iteration 890: 0.101120\n",
      "Cost after iteration 891: 0.100968\n",
      "Cost after iteration 892: 0.100817\n",
      "Cost after iteration 893: 0.100667\n",
      "Cost after iteration 894: 0.100516\n",
      "Cost after iteration 895: 0.100367\n",
      "Cost after iteration 896: 0.100217\n",
      "Cost after iteration 897: 0.100068\n",
      "Cost after iteration 898: 0.099920\n",
      "Cost after iteration 899: 0.099772\n",
      "Cost after iteration 900: 0.099625\n",
      "Cost after iteration 901: 0.099478\n",
      "Cost after iteration 902: 0.099331\n",
      "Cost after iteration 903: 0.099185\n",
      "Cost after iteration 904: 0.099039\n",
      "Cost after iteration 905: 0.098894\n",
      "Cost after iteration 906: 0.098749\n",
      "Cost after iteration 907: 0.098605\n",
      "Cost after iteration 908: 0.098461\n",
      "Cost after iteration 909: 0.098318\n",
      "Cost after iteration 910: 0.098175\n",
      "Cost after iteration 911: 0.098032\n",
      "Cost after iteration 912: 0.097890\n",
      "Cost after iteration 913: 0.097748\n",
      "Cost after iteration 914: 0.097607\n",
      "Cost after iteration 915: 0.097466\n",
      "Cost after iteration 916: 0.097326\n",
      "Cost after iteration 917: 0.097186\n",
      "Cost after iteration 918: 0.097046\n",
      "Cost after iteration 919: 0.096907\n",
      "Cost after iteration 920: 0.096768\n",
      "Cost after iteration 921: 0.096630\n",
      "Cost after iteration 922: 0.096492\n",
      "Cost after iteration 923: 0.096354\n",
      "Cost after iteration 924: 0.096217\n",
      "Cost after iteration 925: 0.096080\n",
      "Cost after iteration 926: 0.095944\n",
      "Cost after iteration 927: 0.095808\n",
      "Cost after iteration 928: 0.095672\n",
      "Cost after iteration 929: 0.095537\n",
      "Cost after iteration 930: 0.095402\n",
      "Cost after iteration 931: 0.095268\n",
      "Cost after iteration 932: 0.095134\n",
      "Cost after iteration 933: 0.095000\n",
      "Cost after iteration 934: 0.094867\n",
      "Cost after iteration 935: 0.094734\n",
      "Cost after iteration 936: 0.094601\n",
      "Cost after iteration 937: 0.094469\n",
      "Cost after iteration 938: 0.094337\n",
      "Cost after iteration 939: 0.094206\n",
      "Cost after iteration 940: 0.094075\n",
      "Cost after iteration 941: 0.093944\n",
      "Cost after iteration 942: 0.093814\n",
      "Cost after iteration 943: 0.093684\n",
      "Cost after iteration 944: 0.093554\n",
      "Cost after iteration 945: 0.093425\n",
      "Cost after iteration 946: 0.093296\n",
      "Cost after iteration 947: 0.093168\n",
      "Cost after iteration 948: 0.093039\n",
      "Cost after iteration 949: 0.092912\n",
      "Cost after iteration 950: 0.092784\n",
      "Cost after iteration 951: 0.092657\n",
      "Cost after iteration 952: 0.092530\n",
      "Cost after iteration 953: 0.092404\n",
      "Cost after iteration 954: 0.092278\n",
      "Cost after iteration 955: 0.092152\n",
      "Cost after iteration 956: 0.092026\n",
      "Cost after iteration 957: 0.091901\n",
      "Cost after iteration 958: 0.091776\n",
      "Cost after iteration 959: 0.091652\n",
      "Cost after iteration 960: 0.091528\n",
      "Cost after iteration 961: 0.091404\n",
      "Cost after iteration 962: 0.091281\n",
      "Cost after iteration 963: 0.091158\n",
      "Cost after iteration 964: 0.091035\n",
      "Cost after iteration 965: 0.090912\n",
      "Cost after iteration 966: 0.090790\n",
      "Cost after iteration 967: 0.090668\n",
      "Cost after iteration 968: 0.090547\n",
      "Cost after iteration 969: 0.090426\n",
      "Cost after iteration 970: 0.090305\n",
      "Cost after iteration 971: 0.090184\n",
      "Cost after iteration 972: 0.090064\n",
      "Cost after iteration 973: 0.089944\n",
      "Cost after iteration 974: 0.089824\n",
      "Cost after iteration 975: 0.089705\n",
      "Cost after iteration 976: 0.089586\n",
      "Cost after iteration 977: 0.089467\n",
      "Cost after iteration 978: 0.089348\n",
      "Cost after iteration 979: 0.089230\n",
      "Cost after iteration 980: 0.089112\n",
      "Cost after iteration 981: 0.088995\n",
      "Cost after iteration 982: 0.088878\n",
      "Cost after iteration 983: 0.088761\n",
      "Cost after iteration 984: 0.088644\n",
      "Cost after iteration 985: 0.088528\n",
      "Cost after iteration 986: 0.088412\n",
      "Cost after iteration 987: 0.088296\n",
      "Cost after iteration 988: 0.088180\n",
      "Cost after iteration 989: 0.088065\n",
      "Cost after iteration 990: 0.087950\n",
      "Cost after iteration 991: 0.087835\n",
      "Cost after iteration 992: 0.087721\n",
      "Cost after iteration 993: 0.087607\n",
      "Cost after iteration 994: 0.087493\n",
      "Cost after iteration 995: 0.087380\n",
      "Cost after iteration 996: 0.087266\n",
      "Cost after iteration 997: 0.087153\n",
      "Cost after iteration 998: 0.087041\n",
      "Cost after iteration 999: 0.086928\n",
      "Cost after iteration 1000: 0.086816\n",
      "Cost after iteration 1001: 0.086704\n",
      "Cost after iteration 1002: 0.086592\n",
      "Cost after iteration 1003: 0.086481\n",
      "Cost after iteration 1004: 0.086370\n",
      "Cost after iteration 1005: 0.086259\n",
      "Cost after iteration 1006: 0.086149\n",
      "Cost after iteration 1007: 0.086038\n",
      "Cost after iteration 1008: 0.085928\n",
      "Cost after iteration 1009: 0.085818\n",
      "Cost after iteration 1010: 0.085709\n",
      "Cost after iteration 1011: 0.085600\n",
      "Cost after iteration 1012: 0.085491\n",
      "Cost after iteration 1013: 0.085382\n",
      "Cost after iteration 1014: 0.085273\n",
      "Cost after iteration 1015: 0.085165\n",
      "Cost after iteration 1016: 0.085057\n",
      "Cost after iteration 1017: 0.084949\n",
      "Cost after iteration 1018: 0.084842\n",
      "Cost after iteration 1019: 0.084734\n",
      "Cost after iteration 1020: 0.084627\n",
      "Cost after iteration 1021: 0.084521\n",
      "Cost after iteration 1022: 0.084414\n",
      "Cost after iteration 1023: 0.084308\n",
      "Cost after iteration 1024: 0.084202\n",
      "Cost after iteration 1025: 0.084096\n",
      "Cost after iteration 1026: 0.083990\n",
      "Cost after iteration 1027: 0.083885\n",
      "Cost after iteration 1028: 0.083780\n",
      "Cost after iteration 1029: 0.083675\n",
      "Cost after iteration 1030: 0.083571\n",
      "Cost after iteration 1031: 0.083466\n",
      "Cost after iteration 1032: 0.083362\n",
      "Cost after iteration 1033: 0.083258\n",
      "Cost after iteration 1034: 0.083155\n",
      "Cost after iteration 1035: 0.083051\n",
      "Cost after iteration 1036: 0.082948\n",
      "Cost after iteration 1037: 0.082845\n",
      "Cost after iteration 1038: 0.082742\n",
      "Cost after iteration 1039: 0.082640\n",
      "Cost after iteration 1040: 0.082537\n",
      "Cost after iteration 1041: 0.082435\n",
      "Cost after iteration 1042: 0.082333\n",
      "Cost after iteration 1043: 0.082232\n",
      "Cost after iteration 1044: 0.082130\n",
      "Cost after iteration 1045: 0.082029\n",
      "Cost after iteration 1046: 0.081928\n",
      "Cost after iteration 1047: 0.081827\n",
      "Cost after iteration 1048: 0.081727\n",
      "Cost after iteration 1049: 0.081627\n",
      "Cost after iteration 1050: 0.081526\n",
      "Cost after iteration 1051: 0.081427\n",
      "Cost after iteration 1052: 0.081327\n",
      "Cost after iteration 1053: 0.081227\n",
      "Cost after iteration 1054: 0.081128\n",
      "Cost after iteration 1055: 0.081029\n",
      "Cost after iteration 1056: 0.080930\n",
      "Cost after iteration 1057: 0.080832\n",
      "Cost after iteration 1058: 0.080733\n",
      "Cost after iteration 1059: 0.080635\n",
      "Cost after iteration 1060: 0.080537\n",
      "Cost after iteration 1061: 0.080439\n",
      "Cost after iteration 1062: 0.080342\n",
      "Cost after iteration 1063: 0.080245\n",
      "Cost after iteration 1064: 0.080147\n",
      "Cost after iteration 1065: 0.080050\n",
      "Cost after iteration 1066: 0.079954\n",
      "Cost after iteration 1067: 0.079857\n",
      "Cost after iteration 1068: 0.079761\n",
      "Cost after iteration 1069: 0.079665\n",
      "Cost after iteration 1070: 0.079569\n",
      "Cost after iteration 1071: 0.079473\n",
      "Cost after iteration 1072: 0.079377\n",
      "Cost after iteration 1073: 0.079282\n",
      "Cost after iteration 1074: 0.079187\n",
      "Cost after iteration 1075: 0.079092\n",
      "Cost after iteration 1076: 0.078997\n",
      "Cost after iteration 1077: 0.078903\n",
      "Cost after iteration 1078: 0.078808\n",
      "Cost after iteration 1079: 0.078714\n",
      "Cost after iteration 1080: 0.078620\n",
      "Cost after iteration 1081: 0.078526\n",
      "Cost after iteration 1082: 0.078433\n",
      "Cost after iteration 1083: 0.078339\n",
      "Cost after iteration 1084: 0.078246\n",
      "Cost after iteration 1085: 0.078153\n",
      "Cost after iteration 1086: 0.078060\n",
      "Cost after iteration 1087: 0.077967\n",
      "Cost after iteration 1088: 0.077875\n",
      "Cost after iteration 1089: 0.077783\n",
      "Cost after iteration 1090: 0.077690\n",
      "Cost after iteration 1091: 0.077598\n",
      "Cost after iteration 1092: 0.077507\n",
      "Cost after iteration 1093: 0.077415\n",
      "Cost after iteration 1094: 0.077324\n",
      "Cost after iteration 1095: 0.077233\n",
      "Cost after iteration 1096: 0.077142\n",
      "Cost after iteration 1097: 0.077051\n",
      "Cost after iteration 1098: 0.076960\n",
      "Cost after iteration 1099: 0.076869\n",
      "Cost after iteration 1100: 0.076779\n",
      "Cost after iteration 1101: 0.076689\n",
      "Cost after iteration 1102: 0.076599\n",
      "Cost after iteration 1103: 0.076509\n",
      "Cost after iteration 1104: 0.076420\n",
      "Cost after iteration 1105: 0.076330\n",
      "Cost after iteration 1106: 0.076241\n",
      "Cost after iteration 1107: 0.076152\n",
      "Cost after iteration 1108: 0.076063\n",
      "Cost after iteration 1109: 0.075974\n",
      "Cost after iteration 1110: 0.075886\n",
      "Cost after iteration 1111: 0.075797\n",
      "Cost after iteration 1112: 0.075709\n",
      "Cost after iteration 1113: 0.075621\n",
      "Cost after iteration 1114: 0.075533\n",
      "Cost after iteration 1115: 0.075445\n",
      "Cost after iteration 1116: 0.075358\n",
      "Cost after iteration 1117: 0.075270\n",
      "Cost after iteration 1118: 0.075183\n",
      "Cost after iteration 1119: 0.075096\n",
      "Cost after iteration 1120: 0.075009\n",
      "Cost after iteration 1121: 0.074922\n",
      "Cost after iteration 1122: 0.074836\n",
      "Cost after iteration 1123: 0.074749\n",
      "Cost after iteration 1124: 0.074663\n",
      "Cost after iteration 1125: 0.074577\n",
      "Cost after iteration 1126: 0.074491\n",
      "Cost after iteration 1127: 0.074405\n",
      "Cost after iteration 1128: 0.074320\n",
      "Cost after iteration 1129: 0.074234\n",
      "Cost after iteration 1130: 0.074149\n",
      "Cost after iteration 1131: 0.074064\n",
      "Cost after iteration 1132: 0.073979\n",
      "Cost after iteration 1133: 0.073894\n",
      "Cost after iteration 1134: 0.073809\n",
      "Cost after iteration 1135: 0.073725\n",
      "Cost after iteration 1136: 0.073640\n",
      "Cost after iteration 1137: 0.073556\n",
      "Cost after iteration 1138: 0.073472\n",
      "Cost after iteration 1139: 0.073388\n",
      "Cost after iteration 1140: 0.073305\n",
      "Cost after iteration 1141: 0.073221\n",
      "Cost after iteration 1142: 0.073138\n",
      "Cost after iteration 1143: 0.073054\n",
      "Cost after iteration 1144: 0.072971\n",
      "Cost after iteration 1145: 0.072888\n",
      "Cost after iteration 1146: 0.072805\n",
      "Cost after iteration 1147: 0.072723\n",
      "Cost after iteration 1148: 0.072640\n",
      "Cost after iteration 1149: 0.072558\n",
      "Cost after iteration 1150: 0.072476\n",
      "Cost after iteration 1151: 0.072393\n",
      "Cost after iteration 1152: 0.072312\n",
      "Cost after iteration 1153: 0.072230\n",
      "Cost after iteration 1154: 0.072148\n",
      "Cost after iteration 1155: 0.072067\n",
      "Cost after iteration 1156: 0.071985\n",
      "Cost after iteration 1157: 0.071904\n",
      "Cost after iteration 1158: 0.071823\n",
      "Cost after iteration 1159: 0.071742\n",
      "Cost after iteration 1160: 0.071661\n",
      "Cost after iteration 1161: 0.071581\n",
      "Cost after iteration 1162: 0.071500\n",
      "Cost after iteration 1163: 0.071420\n",
      "Cost after iteration 1164: 0.071340\n",
      "Cost after iteration 1165: 0.071260\n",
      "Cost after iteration 1166: 0.071180\n",
      "Cost after iteration 1167: 0.071100\n",
      "Cost after iteration 1168: 0.071020\n",
      "Cost after iteration 1169: 0.070941\n",
      "Cost after iteration 1170: 0.070861\n",
      "Cost after iteration 1171: 0.070782\n",
      "Cost after iteration 1172: 0.070703\n",
      "Cost after iteration 1173: 0.070624\n",
      "Cost after iteration 1174: 0.070545\n",
      "Cost after iteration 1175: 0.070467\n",
      "Cost after iteration 1176: 0.070388\n",
      "Cost after iteration 1177: 0.070310\n",
      "Cost after iteration 1178: 0.070231\n",
      "Cost after iteration 1179: 0.070153\n",
      "Cost after iteration 1180: 0.070075\n",
      "Cost after iteration 1181: 0.069997\n",
      "Cost after iteration 1182: 0.069920\n",
      "Cost after iteration 1183: 0.069842\n",
      "Cost after iteration 1184: 0.069765\n",
      "Cost after iteration 1185: 0.069687\n",
      "Cost after iteration 1186: 0.069610\n",
      "Cost after iteration 1187: 0.069533\n",
      "Cost after iteration 1188: 0.069456\n",
      "Cost after iteration 1189: 0.069379\n",
      "Cost after iteration 1190: 0.069303\n",
      "Cost after iteration 1191: 0.069226\n",
      "Cost after iteration 1192: 0.069150\n",
      "Cost after iteration 1193: 0.069073\n",
      "Cost after iteration 1194: 0.068997\n",
      "Cost after iteration 1195: 0.068921\n",
      "Cost after iteration 1196: 0.068845\n",
      "Cost after iteration 1197: 0.068769\n",
      "Cost after iteration 1198: 0.068694\n",
      "Cost after iteration 1199: 0.068618\n",
      "Cost after iteration 1200: 0.068543\n",
      "Cost after iteration 1201: 0.068468\n",
      "Cost after iteration 1202: 0.068392\n",
      "Cost after iteration 1203: 0.068317\n",
      "Cost after iteration 1204: 0.068242\n",
      "Cost after iteration 1205: 0.068168\n",
      "Cost after iteration 1206: 0.068093\n",
      "Cost after iteration 1207: 0.068019\n",
      "Cost after iteration 1208: 0.067944\n",
      "Cost after iteration 1209: 0.067870\n",
      "Cost after iteration 1210: 0.067796\n",
      "Cost after iteration 1211: 0.067722\n",
      "Cost after iteration 1212: 0.067648\n",
      "Cost after iteration 1213: 0.067574\n",
      "Cost after iteration 1214: 0.067500\n",
      "Cost after iteration 1215: 0.067427\n",
      "Cost after iteration 1216: 0.067353\n",
      "Cost after iteration 1217: 0.067280\n",
      "Cost after iteration 1218: 0.067207\n",
      "Cost after iteration 1219: 0.067134\n",
      "Cost after iteration 1220: 0.067061\n",
      "Cost after iteration 1221: 0.066988\n",
      "Cost after iteration 1222: 0.066915\n",
      "Cost after iteration 1223: 0.066843\n",
      "Cost after iteration 1224: 0.066770\n",
      "Cost after iteration 1225: 0.066698\n",
      "Cost after iteration 1226: 0.066626\n",
      "Cost after iteration 1227: 0.066553\n",
      "Cost after iteration 1228: 0.066481\n",
      "Cost after iteration 1229: 0.066410\n",
      "Cost after iteration 1230: 0.066338\n",
      "Cost after iteration 1231: 0.066266\n",
      "Cost after iteration 1232: 0.066195\n",
      "Cost after iteration 1233: 0.066123\n",
      "Cost after iteration 1234: 0.066052\n",
      "Cost after iteration 1235: 0.065981\n",
      "Cost after iteration 1236: 0.065910\n",
      "Cost after iteration 1237: 0.065839\n",
      "Cost after iteration 1238: 0.065768\n",
      "Cost after iteration 1239: 0.065697\n",
      "Cost after iteration 1240: 0.065626\n",
      "Cost after iteration 1241: 0.065556\n",
      "Cost after iteration 1242: 0.065485\n",
      "Cost after iteration 1243: 0.065415\n",
      "Cost after iteration 1244: 0.065345\n",
      "Cost after iteration 1245: 0.065275\n",
      "Cost after iteration 1246: 0.065205\n",
      "Cost after iteration 1247: 0.065135\n",
      "Cost after iteration 1248: 0.065065\n",
      "Cost after iteration 1249: 0.064996\n",
      "Cost after iteration 1250: 0.064926\n",
      "Cost after iteration 1251: 0.064857\n",
      "Cost after iteration 1252: 0.064787\n",
      "Cost after iteration 1253: 0.064718\n",
      "Cost after iteration 1254: 0.064649\n",
      "Cost after iteration 1255: 0.064580\n",
      "Cost after iteration 1256: 0.064511\n",
      "Cost after iteration 1257: 0.064442\n",
      "Cost after iteration 1258: 0.064374\n",
      "Cost after iteration 1259: 0.064305\n",
      "Cost after iteration 1260: 0.064237\n",
      "Cost after iteration 1261: 0.064168\n",
      "Cost after iteration 1262: 0.064100\n",
      "Cost after iteration 1263: 0.064032\n",
      "Cost after iteration 1264: 0.063964\n",
      "Cost after iteration 1265: 0.063896\n",
      "Cost after iteration 1266: 0.063828\n",
      "Cost after iteration 1267: 0.063760\n",
      "Cost after iteration 1268: 0.063693\n",
      "Cost after iteration 1269: 0.063625\n",
      "Cost after iteration 1270: 0.063558\n",
      "Cost after iteration 1271: 0.063491\n",
      "Cost after iteration 1272: 0.063423\n",
      "Cost after iteration 1273: 0.063356\n",
      "Cost after iteration 1274: 0.063289\n",
      "Cost after iteration 1275: 0.063222\n",
      "Cost after iteration 1276: 0.063156\n",
      "Cost after iteration 1277: 0.063089\n",
      "Cost after iteration 1278: 0.063022\n",
      "Cost after iteration 1279: 0.062956\n",
      "Cost after iteration 1280: 0.062889\n",
      "Cost after iteration 1281: 0.062823\n",
      "Cost after iteration 1282: 0.062757\n",
      "Cost after iteration 1283: 0.062691\n",
      "Cost after iteration 1284: 0.062625\n",
      "Cost after iteration 1285: 0.062559\n",
      "Cost after iteration 1286: 0.062493\n",
      "Cost after iteration 1287: 0.062428\n",
      "Cost after iteration 1288: 0.062362\n",
      "Cost after iteration 1289: 0.062296\n",
      "Cost after iteration 1290: 0.062231\n",
      "Cost after iteration 1291: 0.062166\n",
      "Cost after iteration 1292: 0.062101\n",
      "Cost after iteration 1293: 0.062035\n",
      "Cost after iteration 1294: 0.061970\n",
      "Cost after iteration 1295: 0.061906\n",
      "Cost after iteration 1296: 0.061841\n",
      "Cost after iteration 1297: 0.061776\n",
      "Cost after iteration 1298: 0.061711\n",
      "Cost after iteration 1299: 0.061647\n",
      "Cost after iteration 1300: 0.061583\n",
      "Cost after iteration 1301: 0.061518\n",
      "Cost after iteration 1302: 0.061454\n",
      "Cost after iteration 1303: 0.061390\n",
      "Cost after iteration 1304: 0.061326\n",
      "Cost after iteration 1305: 0.061262\n",
      "Cost after iteration 1306: 0.061198\n",
      "Cost after iteration 1307: 0.061134\n",
      "Cost after iteration 1308: 0.061071\n",
      "Cost after iteration 1309: 0.061007\n",
      "Cost after iteration 1310: 0.060944\n",
      "Cost after iteration 1311: 0.060880\n",
      "Cost after iteration 1312: 0.060817\n",
      "Cost after iteration 1313: 0.060754\n",
      "Cost after iteration 1314: 0.060691\n",
      "Cost after iteration 1315: 0.060628\n",
      "Cost after iteration 1316: 0.060565\n",
      "Cost after iteration 1317: 0.060502\n",
      "Cost after iteration 1318: 0.060439\n",
      "Cost after iteration 1319: 0.060377\n",
      "Cost after iteration 1320: 0.060314\n",
      "Cost after iteration 1321: 0.060252\n",
      "Cost after iteration 1322: 0.060189\n",
      "Cost after iteration 1323: 0.060127\n",
      "Cost after iteration 1324: 0.060065\n",
      "Cost after iteration 1325: 0.060003\n",
      "Cost after iteration 1326: 0.059941\n",
      "Cost after iteration 1327: 0.059879\n",
      "Cost after iteration 1328: 0.059817\n",
      "Cost after iteration 1329: 0.059755\n",
      "Cost after iteration 1330: 0.059693\n",
      "Cost after iteration 1331: 0.059632\n",
      "Cost after iteration 1332: 0.059570\n",
      "Cost after iteration 1333: 0.059509\n",
      "Cost after iteration 1334: 0.059448\n",
      "Cost after iteration 1335: 0.059387\n",
      "Cost after iteration 1336: 0.059325\n",
      "Cost after iteration 1337: 0.059264\n",
      "Cost after iteration 1338: 0.059203\n",
      "Cost after iteration 1339: 0.059143\n",
      "Cost after iteration 1340: 0.059082\n",
      "Cost after iteration 1341: 0.059021\n",
      "Cost after iteration 1342: 0.058961\n",
      "Cost after iteration 1343: 0.058900\n",
      "Cost after iteration 1344: 0.058840\n",
      "Cost after iteration 1345: 0.058779\n",
      "Cost after iteration 1346: 0.058719\n",
      "Cost after iteration 1347: 0.058659\n",
      "Cost after iteration 1348: 0.058599\n",
      "Cost after iteration 1349: 0.058539\n",
      "Cost after iteration 1350: 0.058479\n",
      "Cost after iteration 1351: 0.058419\n",
      "Cost after iteration 1352: 0.058359\n",
      "Cost after iteration 1353: 0.058300\n",
      "Cost after iteration 1354: 0.058240\n",
      "Cost after iteration 1355: 0.058181\n",
      "Cost after iteration 1356: 0.058121\n",
      "Cost after iteration 1357: 0.058062\n",
      "Cost after iteration 1358: 0.058003\n",
      "Cost after iteration 1359: 0.057944\n",
      "Cost after iteration 1360: 0.057885\n",
      "Cost after iteration 1361: 0.057826\n",
      "Cost after iteration 1362: 0.057767\n",
      "Cost after iteration 1363: 0.057708\n",
      "Cost after iteration 1364: 0.057649\n",
      "Cost after iteration 1365: 0.057591\n",
      "Cost after iteration 1366: 0.057532\n",
      "Cost after iteration 1367: 0.057474\n",
      "Cost after iteration 1368: 0.057415\n",
      "Cost after iteration 1369: 0.057357\n",
      "Cost after iteration 1370: 0.057299\n",
      "Cost after iteration 1371: 0.057240\n",
      "Cost after iteration 1372: 0.057182\n",
      "Cost after iteration 1373: 0.057124\n",
      "Cost after iteration 1374: 0.057066\n",
      "Cost after iteration 1375: 0.057009\n",
      "Cost after iteration 1376: 0.056951\n",
      "Cost after iteration 1377: 0.056893\n",
      "Cost after iteration 1378: 0.056836\n",
      "Cost after iteration 1379: 0.056778\n",
      "Cost after iteration 1380: 0.056721\n",
      "Cost after iteration 1381: 0.056663\n",
      "Cost after iteration 1382: 0.056606\n",
      "Cost after iteration 1383: 0.056549\n",
      "Cost after iteration 1384: 0.056492\n",
      "Cost after iteration 1385: 0.056435\n",
      "Cost after iteration 1386: 0.056378\n",
      "Cost after iteration 1387: 0.056321\n",
      "Cost after iteration 1388: 0.056264\n",
      "Cost after iteration 1389: 0.056207\n",
      "Cost after iteration 1390: 0.056151\n",
      "Cost after iteration 1391: 0.056094\n",
      "Cost after iteration 1392: 0.056038\n",
      "Cost after iteration 1393: 0.055981\n",
      "Cost after iteration 1394: 0.055925\n",
      "Cost after iteration 1395: 0.055869\n",
      "Cost after iteration 1396: 0.055812\n",
      "Cost after iteration 1397: 0.055756\n",
      "Cost after iteration 1398: 0.055700\n",
      "Cost after iteration 1399: 0.055644\n",
      "Cost after iteration 1400: 0.055588\n",
      "Cost after iteration 1401: 0.055533\n",
      "Cost after iteration 1402: 0.055477\n",
      "Cost after iteration 1403: 0.055421\n",
      "Cost after iteration 1404: 0.055366\n",
      "Cost after iteration 1405: 0.055310\n",
      "Cost after iteration 1406: 0.055255\n",
      "Cost after iteration 1407: 0.055199\n",
      "Cost after iteration 1408: 0.055144\n",
      "Cost after iteration 1409: 0.055089\n",
      "Cost after iteration 1410: 0.055034\n",
      "Cost after iteration 1411: 0.054979\n",
      "Cost after iteration 1412: 0.054924\n",
      "Cost after iteration 1413: 0.054869\n",
      "Cost after iteration 1414: 0.054814\n",
      "Cost after iteration 1415: 0.054759\n",
      "Cost after iteration 1416: 0.054705\n",
      "Cost after iteration 1417: 0.054650\n",
      "Cost after iteration 1418: 0.054596\n",
      "Cost after iteration 1419: 0.054541\n",
      "Cost after iteration 1420: 0.054487\n",
      "Cost after iteration 1421: 0.054433\n",
      "Cost after iteration 1422: 0.054378\n",
      "Cost after iteration 1423: 0.054324\n",
      "Cost after iteration 1424: 0.054270\n",
      "Cost after iteration 1425: 0.054216\n",
      "Cost after iteration 1426: 0.054162\n",
      "Cost after iteration 1427: 0.054108\n",
      "Cost after iteration 1428: 0.054054\n",
      "Cost after iteration 1429: 0.054001\n",
      "Cost after iteration 1430: 0.053947\n",
      "Cost after iteration 1431: 0.053893\n",
      "Cost after iteration 1432: 0.053840\n",
      "Cost after iteration 1433: 0.053787\n",
      "Cost after iteration 1434: 0.053733\n",
      "Cost after iteration 1435: 0.053680\n",
      "Cost after iteration 1436: 0.053627\n",
      "Cost after iteration 1437: 0.053574\n",
      "Cost after iteration 1438: 0.053520\n",
      "Cost after iteration 1439: 0.053467\n",
      "Cost after iteration 1440: 0.053414\n",
      "Cost after iteration 1441: 0.053362\n",
      "Cost after iteration 1442: 0.053309\n",
      "Cost after iteration 1443: 0.053256\n",
      "Cost after iteration 1444: 0.053203\n",
      "Cost after iteration 1445: 0.053151\n",
      "Cost after iteration 1446: 0.053098\n",
      "Cost after iteration 1447: 0.053046\n",
      "Cost after iteration 1448: 0.052993\n",
      "Cost after iteration 1449: 0.052941\n",
      "Cost after iteration 1450: 0.052889\n",
      "Cost after iteration 1451: 0.052837\n",
      "Cost after iteration 1452: 0.052785\n",
      "Cost after iteration 1453: 0.052733\n",
      "Cost after iteration 1454: 0.052681\n",
      "Cost after iteration 1455: 0.052629\n",
      "Cost after iteration 1456: 0.052577\n",
      "Cost after iteration 1457: 0.052525\n",
      "Cost after iteration 1458: 0.052473\n",
      "Cost after iteration 1459: 0.052422\n",
      "Cost after iteration 1460: 0.052370\n",
      "Cost after iteration 1461: 0.052319\n",
      "Cost after iteration 1462: 0.052267\n",
      "Cost after iteration 1463: 0.052216\n",
      "Cost after iteration 1464: 0.052165\n",
      "Cost after iteration 1465: 0.052113\n",
      "Cost after iteration 1466: 0.052062\n",
      "Cost after iteration 1467: 0.052011\n",
      "Cost after iteration 1468: 0.051960\n",
      "Cost after iteration 1469: 0.051909\n",
      "Cost after iteration 1470: 0.051858\n",
      "Cost after iteration 1471: 0.051808\n",
      "Cost after iteration 1472: 0.051757\n",
      "Cost after iteration 1473: 0.051706\n",
      "Cost after iteration 1474: 0.051655\n",
      "Cost after iteration 1475: 0.051605\n",
      "Cost after iteration 1476: 0.051554\n",
      "Cost after iteration 1477: 0.051504\n",
      "Cost after iteration 1478: 0.051454\n",
      "Cost after iteration 1479: 0.051403\n",
      "Cost after iteration 1480: 0.051353\n",
      "Cost after iteration 1481: 0.051303\n",
      "Cost after iteration 1482: 0.051253\n",
      "Cost after iteration 1483: 0.051203\n",
      "Cost after iteration 1484: 0.051153\n",
      "Cost after iteration 1485: 0.051103\n",
      "Cost after iteration 1486: 0.051053\n",
      "Cost after iteration 1487: 0.051003\n",
      "Cost after iteration 1488: 0.050954\n",
      "Cost after iteration 1489: 0.050904\n",
      "Cost after iteration 1490: 0.050854\n",
      "Cost after iteration 1491: 0.050805\n",
      "Cost after iteration 1492: 0.050755\n",
      "Cost after iteration 1493: 0.050706\n",
      "Cost after iteration 1494: 0.050657\n",
      "Cost after iteration 1495: 0.050607\n",
      "Cost after iteration 1496: 0.050558\n",
      "Cost after iteration 1497: 0.050509\n",
      "Cost after iteration 1498: 0.050460\n",
      "Cost after iteration 1499: 0.050411\n",
      "Cost after iteration 1500: 0.050362\n",
      "Cost after iteration 1501: 0.050313\n",
      "Cost after iteration 1502: 0.050264\n",
      "Cost after iteration 1503: 0.050216\n",
      "Cost after iteration 1504: 0.050167\n",
      "Cost after iteration 1505: 0.050118\n",
      "Cost after iteration 1506: 0.050070\n",
      "Cost after iteration 1507: 0.050021\n",
      "Cost after iteration 1508: 0.049973\n",
      "Cost after iteration 1509: 0.049924\n",
      "Cost after iteration 1510: 0.049876\n",
      "Cost after iteration 1511: 0.049828\n",
      "Cost after iteration 1512: 0.049780\n",
      "Cost after iteration 1513: 0.049731\n",
      "Cost after iteration 1514: 0.049683\n",
      "Cost after iteration 1515: 0.049635\n",
      "Cost after iteration 1516: 0.049587\n",
      "Cost after iteration 1517: 0.049539\n",
      "Cost after iteration 1518: 0.049492\n",
      "Cost after iteration 1519: 0.049444\n",
      "Cost after iteration 1520: 0.049396\n",
      "Cost after iteration 1521: 0.049348\n",
      "Cost after iteration 1522: 0.049301\n",
      "Cost after iteration 1523: 0.049253\n",
      "Cost after iteration 1524: 0.049206\n",
      "Cost after iteration 1525: 0.049158\n",
      "Cost after iteration 1526: 0.049111\n",
      "Cost after iteration 1527: 0.049064\n",
      "Cost after iteration 1528: 0.049017\n",
      "Cost after iteration 1529: 0.048969\n",
      "Cost after iteration 1530: 0.048922\n",
      "Cost after iteration 1531: 0.048875\n",
      "Cost after iteration 1532: 0.048828\n",
      "Cost after iteration 1533: 0.048781\n",
      "Cost after iteration 1534: 0.048734\n",
      "Cost after iteration 1535: 0.048688\n",
      "Cost after iteration 1536: 0.048641\n",
      "Cost after iteration 1537: 0.048594\n",
      "Cost after iteration 1538: 0.048548\n",
      "Cost after iteration 1539: 0.048501\n",
      "Cost after iteration 1540: 0.048454\n",
      "Cost after iteration 1541: 0.048408\n",
      "Cost after iteration 1542: 0.048362\n",
      "Cost after iteration 1543: 0.048315\n",
      "Cost after iteration 1544: 0.048269\n",
      "Cost after iteration 1545: 0.048223\n",
      "Cost after iteration 1546: 0.048177\n",
      "Cost after iteration 1547: 0.048130\n",
      "Cost after iteration 1548: 0.048084\n",
      "Cost after iteration 1549: 0.048038\n",
      "Cost after iteration 1550: 0.047992\n",
      "Cost after iteration 1551: 0.047947\n",
      "Cost after iteration 1552: 0.047901\n",
      "Cost after iteration 1553: 0.047855\n",
      "Cost after iteration 1554: 0.047809\n",
      "Cost after iteration 1555: 0.047764\n",
      "Cost after iteration 1556: 0.047718\n",
      "Cost after iteration 1557: 0.047672\n",
      "Cost after iteration 1558: 0.047627\n",
      "Cost after iteration 1559: 0.047581\n",
      "Cost after iteration 1560: 0.047536\n",
      "Cost after iteration 1561: 0.047491\n",
      "Cost after iteration 1562: 0.047446\n",
      "Cost after iteration 1563: 0.047400\n",
      "Cost after iteration 1564: 0.047355\n",
      "Cost after iteration 1565: 0.047310\n",
      "Cost after iteration 1566: 0.047265\n",
      "Cost after iteration 1567: 0.047220\n",
      "Cost after iteration 1568: 0.047175\n",
      "Cost after iteration 1569: 0.047130\n",
      "Cost after iteration 1570: 0.047086\n",
      "Cost after iteration 1571: 0.047041\n",
      "Cost after iteration 1572: 0.046996\n",
      "Cost after iteration 1573: 0.046951\n",
      "Cost after iteration 1574: 0.046907\n",
      "Cost after iteration 1575: 0.046862\n",
      "Cost after iteration 1576: 0.046818\n",
      "Cost after iteration 1577: 0.046773\n",
      "Cost after iteration 1578: 0.046729\n",
      "Cost after iteration 1579: 0.046685\n",
      "Cost after iteration 1580: 0.046640\n",
      "Cost after iteration 1581: 0.046596\n",
      "Cost after iteration 1582: 0.046552\n",
      "Cost after iteration 1583: 0.046508\n",
      "Cost after iteration 1584: 0.046464\n",
      "Cost after iteration 1585: 0.046420\n",
      "Cost after iteration 1586: 0.046376\n",
      "Cost after iteration 1587: 0.046332\n",
      "Cost after iteration 1588: 0.046288\n",
      "Cost after iteration 1589: 0.046245\n",
      "Cost after iteration 1590: 0.046201\n",
      "Cost after iteration 1591: 0.046157\n",
      "Cost after iteration 1592: 0.046114\n",
      "Cost after iteration 1593: 0.046070\n",
      "Cost after iteration 1594: 0.046027\n",
      "Cost after iteration 1595: 0.045983\n",
      "Cost after iteration 1596: 0.045940\n",
      "Cost after iteration 1597: 0.045896\n",
      "Cost after iteration 1598: 0.045853\n",
      "Cost after iteration 1599: 0.045810\n",
      "Cost after iteration 1600: 0.045767\n",
      "Cost after iteration 1601: 0.045723\n",
      "Cost after iteration 1602: 0.045680\n",
      "Cost after iteration 1603: 0.045637\n",
      "Cost after iteration 1604: 0.045594\n",
      "Cost after iteration 1605: 0.045552\n",
      "Cost after iteration 1606: 0.045509\n",
      "Cost after iteration 1607: 0.045466\n",
      "Cost after iteration 1608: 0.045423\n",
      "Cost after iteration 1609: 0.045380\n",
      "Cost after iteration 1610: 0.045338\n",
      "Cost after iteration 1611: 0.045295\n",
      "Cost after iteration 1612: 0.045253\n",
      "Cost after iteration 1613: 0.045210\n",
      "Cost after iteration 1614: 0.045168\n",
      "Cost after iteration 1615: 0.045125\n",
      "Cost after iteration 1616: 0.045083\n",
      "Cost after iteration 1617: 0.045041\n",
      "Cost after iteration 1618: 0.044998\n",
      "Cost after iteration 1619: 0.044956\n",
      "Cost after iteration 1620: 0.044914\n",
      "Cost after iteration 1621: 0.044872\n",
      "Cost after iteration 1622: 0.044830\n",
      "Cost after iteration 1623: 0.044788\n",
      "Cost after iteration 1624: 0.044746\n",
      "Cost after iteration 1625: 0.044704\n",
      "Cost after iteration 1626: 0.044662\n",
      "Cost after iteration 1627: 0.044620\n",
      "Cost after iteration 1628: 0.044579\n",
      "Cost after iteration 1629: 0.044537\n",
      "Cost after iteration 1630: 0.044495\n",
      "Cost after iteration 1631: 0.044454\n",
      "Cost after iteration 1632: 0.044412\n",
      "Cost after iteration 1633: 0.044371\n",
      "Cost after iteration 1634: 0.044329\n",
      "Cost after iteration 1635: 0.044288\n",
      "Cost after iteration 1636: 0.044247\n",
      "Cost after iteration 1637: 0.044205\n",
      "Cost after iteration 1638: 0.044164\n",
      "Cost after iteration 1639: 0.044123\n",
      "Cost after iteration 1640: 0.044082\n",
      "Cost after iteration 1641: 0.044041\n",
      "Cost after iteration 1642: 0.044000\n",
      "Cost after iteration 1643: 0.043959\n",
      "Cost after iteration 1644: 0.043918\n",
      "Cost after iteration 1645: 0.043877\n",
      "Cost after iteration 1646: 0.043836\n",
      "Cost after iteration 1647: 0.043795\n",
      "Cost after iteration 1648: 0.043755\n",
      "Cost after iteration 1649: 0.043714\n",
      "Cost after iteration 1650: 0.043673\n",
      "Cost after iteration 1651: 0.043633\n",
      "Cost after iteration 1652: 0.043592\n",
      "Cost after iteration 1653: 0.043552\n",
      "Cost after iteration 1654: 0.043511\n",
      "Cost after iteration 1655: 0.043471\n",
      "Cost after iteration 1656: 0.043430\n",
      "Cost after iteration 1657: 0.043390\n",
      "Cost after iteration 1658: 0.043350\n",
      "Cost after iteration 1659: 0.043310\n",
      "Cost after iteration 1660: 0.043269\n",
      "Cost after iteration 1661: 0.043229\n",
      "Cost after iteration 1662: 0.043189\n",
      "Cost after iteration 1663: 0.043149\n",
      "Cost after iteration 1664: 0.043109\n",
      "Cost after iteration 1665: 0.043069\n",
      "Cost after iteration 1666: 0.043030\n",
      "Cost after iteration 1667: 0.042990\n",
      "Cost after iteration 1668: 0.042950\n",
      "Cost after iteration 1669: 0.042910\n",
      "Cost after iteration 1670: 0.042871\n",
      "Cost after iteration 1671: 0.042831\n",
      "Cost after iteration 1672: 0.042791\n",
      "Cost after iteration 1673: 0.042752\n",
      "Cost after iteration 1674: 0.042712\n",
      "Cost after iteration 1675: 0.042673\n",
      "Cost after iteration 1676: 0.042633\n",
      "Cost after iteration 1677: 0.042594\n",
      "Cost after iteration 1678: 0.042555\n",
      "Cost after iteration 1679: 0.042516\n",
      "Cost after iteration 1680: 0.042476\n",
      "Cost after iteration 1681: 0.042437\n",
      "Cost after iteration 1682: 0.042398\n",
      "Cost after iteration 1683: 0.042359\n",
      "Cost after iteration 1684: 0.042320\n",
      "Cost after iteration 1685: 0.042281\n",
      "Cost after iteration 1686: 0.042242\n",
      "Cost after iteration 1687: 0.042203\n",
      "Cost after iteration 1688: 0.042164\n",
      "Cost after iteration 1689: 0.042126\n",
      "Cost after iteration 1690: 0.042087\n",
      "Cost after iteration 1691: 0.042048\n",
      "Cost after iteration 1692: 0.042010\n",
      "Cost after iteration 1693: 0.041971\n",
      "Cost after iteration 1694: 0.041932\n",
      "Cost after iteration 1695: 0.041894\n",
      "Cost after iteration 1696: 0.041855\n",
      "Cost after iteration 1697: 0.041817\n",
      "Cost after iteration 1698: 0.041779\n",
      "Cost after iteration 1699: 0.041740\n",
      "Cost after iteration 1700: 0.041702\n",
      "Cost after iteration 1701: 0.041664\n",
      "Cost after iteration 1702: 0.041625\n",
      "Cost after iteration 1703: 0.041587\n",
      "Cost after iteration 1704: 0.041549\n",
      "Cost after iteration 1705: 0.041511\n",
      "Cost after iteration 1706: 0.041473\n",
      "Cost after iteration 1707: 0.041435\n",
      "Cost after iteration 1708: 0.041397\n",
      "Cost after iteration 1709: 0.041359\n",
      "Cost after iteration 1710: 0.041322\n",
      "Cost after iteration 1711: 0.041284\n",
      "Cost after iteration 1712: 0.041246\n",
      "Cost after iteration 1713: 0.041208\n",
      "Cost after iteration 1714: 0.041171\n",
      "Cost after iteration 1715: 0.041133\n",
      "Cost after iteration 1716: 0.041095\n",
      "Cost after iteration 1717: 0.041058\n",
      "Cost after iteration 1718: 0.041020\n",
      "Cost after iteration 1719: 0.040983\n",
      "Cost after iteration 1720: 0.040946\n",
      "Cost after iteration 1721: 0.040908\n",
      "Cost after iteration 1722: 0.040871\n",
      "Cost after iteration 1723: 0.040834\n",
      "Cost after iteration 1724: 0.040796\n",
      "Cost after iteration 1725: 0.040759\n",
      "Cost after iteration 1726: 0.040722\n",
      "Cost after iteration 1727: 0.040685\n",
      "Cost after iteration 1728: 0.040648\n",
      "Cost after iteration 1729: 0.040611\n",
      "Cost after iteration 1730: 0.040574\n",
      "Cost after iteration 1731: 0.040537\n",
      "Cost after iteration 1732: 0.040500\n",
      "Cost after iteration 1733: 0.040463\n",
      "Cost after iteration 1734: 0.040427\n",
      "Cost after iteration 1735: 0.040390\n",
      "Cost after iteration 1736: 0.040353\n",
      "Cost after iteration 1737: 0.040317\n",
      "Cost after iteration 1738: 0.040280\n",
      "Cost after iteration 1739: 0.040243\n",
      "Cost after iteration 1740: 0.040207\n",
      "Cost after iteration 1741: 0.040170\n",
      "Cost after iteration 1742: 0.040134\n",
      "Cost after iteration 1743: 0.040097\n",
      "Cost after iteration 1744: 0.040061\n",
      "Cost after iteration 1745: 0.040025\n",
      "Cost after iteration 1746: 0.039988\n",
      "Cost after iteration 1747: 0.039952\n",
      "Cost after iteration 1748: 0.039916\n",
      "Cost after iteration 1749: 0.039880\n",
      "Cost after iteration 1750: 0.039844\n",
      "Cost after iteration 1751: 0.039808\n",
      "Cost after iteration 1752: 0.039772\n",
      "Cost after iteration 1753: 0.039736\n",
      "Cost after iteration 1754: 0.039700\n",
      "Cost after iteration 1755: 0.039664\n",
      "Cost after iteration 1756: 0.039628\n",
      "Cost after iteration 1757: 0.039592\n",
      "Cost after iteration 1758: 0.039556\n",
      "Cost after iteration 1759: 0.039521\n",
      "Cost after iteration 1760: 0.039485\n",
      "Cost after iteration 1761: 0.039449\n",
      "Cost after iteration 1762: 0.039414\n",
      "Cost after iteration 1763: 0.039378\n",
      "Cost after iteration 1764: 0.039343\n",
      "Cost after iteration 1765: 0.039307\n",
      "Cost after iteration 1766: 0.039272\n",
      "Cost after iteration 1767: 0.039236\n",
      "Cost after iteration 1768: 0.039201\n",
      "Cost after iteration 1769: 0.039166\n",
      "Cost after iteration 1770: 0.039130\n",
      "Cost after iteration 1771: 0.039095\n",
      "Cost after iteration 1772: 0.039060\n",
      "Cost after iteration 1773: 0.039025\n",
      "Cost after iteration 1774: 0.038990\n",
      "Cost after iteration 1775: 0.038955\n",
      "Cost after iteration 1776: 0.038920\n",
      "Cost after iteration 1777: 0.038885\n",
      "Cost after iteration 1778: 0.038850\n",
      "Cost after iteration 1779: 0.038815\n",
      "Cost after iteration 1780: 0.038780\n",
      "Cost after iteration 1781: 0.038745\n",
      "Cost after iteration 1782: 0.038710\n",
      "Cost after iteration 1783: 0.038675\n",
      "Cost after iteration 1784: 0.038641\n",
      "Cost after iteration 1785: 0.038606\n",
      "Cost after iteration 1786: 0.038571\n",
      "Cost after iteration 1787: 0.038537\n",
      "Cost after iteration 1788: 0.038502\n",
      "Cost after iteration 1789: 0.038468\n",
      "Cost after iteration 1790: 0.038433\n",
      "Cost after iteration 1791: 0.038399\n",
      "Cost after iteration 1792: 0.038365\n",
      "Cost after iteration 1793: 0.038330\n",
      "Cost after iteration 1794: 0.038296\n",
      "Cost after iteration 1795: 0.038262\n",
      "Cost after iteration 1796: 0.038227\n",
      "Cost after iteration 1797: 0.038193\n",
      "Cost after iteration 1798: 0.038159\n",
      "Cost after iteration 1799: 0.038125\n",
      "Cost after iteration 1800: 0.038091\n",
      "Cost after iteration 1801: 0.038057\n",
      "Cost after iteration 1802: 0.038023\n",
      "Cost after iteration 1803: 0.037989\n",
      "Cost after iteration 1804: 0.037955\n",
      "Cost after iteration 1805: 0.037921\n",
      "Cost after iteration 1806: 0.037887\n",
      "Cost after iteration 1807: 0.037853\n",
      "Cost after iteration 1808: 0.037820\n",
      "Cost after iteration 1809: 0.037786\n",
      "Cost after iteration 1810: 0.037752\n",
      "Cost after iteration 1811: 0.037718\n",
      "Cost after iteration 1812: 0.037685\n",
      "Cost after iteration 1813: 0.037651\n",
      "Cost after iteration 1814: 0.037618\n",
      "Cost after iteration 1815: 0.037584\n",
      "Cost after iteration 1816: 0.037551\n",
      "Cost after iteration 1817: 0.037517\n",
      "Cost after iteration 1818: 0.037484\n",
      "Cost after iteration 1819: 0.037451\n",
      "Cost after iteration 1820: 0.037417\n",
      "Cost after iteration 1821: 0.037384\n",
      "Cost after iteration 1822: 0.037351\n",
      "Cost after iteration 1823: 0.037318\n",
      "Cost after iteration 1824: 0.037284\n",
      "Cost after iteration 1825: 0.037251\n",
      "Cost after iteration 1826: 0.037218\n",
      "Cost after iteration 1827: 0.037185\n",
      "Cost after iteration 1828: 0.037152\n",
      "Cost after iteration 1829: 0.037119\n",
      "Cost after iteration 1830: 0.037086\n",
      "Cost after iteration 1831: 0.037053\n",
      "Cost after iteration 1832: 0.037021\n",
      "Cost after iteration 1833: 0.036988\n",
      "Cost after iteration 1834: 0.036955\n",
      "Cost after iteration 1835: 0.036922\n",
      "Cost after iteration 1836: 0.036890\n",
      "Cost after iteration 1837: 0.036857\n",
      "Cost after iteration 1838: 0.036824\n",
      "Cost after iteration 1839: 0.036792\n",
      "Cost after iteration 1840: 0.036759\n",
      "Cost after iteration 1841: 0.036727\n",
      "Cost after iteration 1842: 0.036694\n",
      "Cost after iteration 1843: 0.036662\n",
      "Cost after iteration 1844: 0.036629\n",
      "Cost after iteration 1845: 0.036597\n",
      "Cost after iteration 1846: 0.036565\n",
      "Cost after iteration 1847: 0.036532\n",
      "Cost after iteration 1848: 0.036500\n",
      "Cost after iteration 1849: 0.036468\n",
      "Cost after iteration 1850: 0.036436\n",
      "Cost after iteration 1851: 0.036403\n",
      "Cost after iteration 1852: 0.036371\n",
      "Cost after iteration 1853: 0.036339\n",
      "Cost after iteration 1854: 0.036307\n",
      "Cost after iteration 1855: 0.036275\n",
      "Cost after iteration 1856: 0.036243\n",
      "Cost after iteration 1857: 0.036211\n",
      "Cost after iteration 1858: 0.036179\n",
      "Cost after iteration 1859: 0.036147\n",
      "Cost after iteration 1860: 0.036116\n",
      "Cost after iteration 1861: 0.036084\n",
      "Cost after iteration 1862: 0.036052\n",
      "Cost after iteration 1863: 0.036020\n",
      "Cost after iteration 1864: 0.035989\n",
      "Cost after iteration 1865: 0.035957\n",
      "Cost after iteration 1866: 0.035925\n",
      "Cost after iteration 1867: 0.035894\n",
      "Cost after iteration 1868: 0.035862\n",
      "Cost after iteration 1869: 0.035831\n",
      "Cost after iteration 1870: 0.035799\n",
      "Cost after iteration 1871: 0.035768\n",
      "Cost after iteration 1872: 0.035737\n",
      "Cost after iteration 1873: 0.035705\n",
      "Cost after iteration 1874: 0.035674\n",
      "Cost after iteration 1875: 0.035643\n",
      "Cost after iteration 1876: 0.035611\n",
      "Cost after iteration 1877: 0.035580\n",
      "Cost after iteration 1878: 0.035549\n",
      "Cost after iteration 1879: 0.035518\n",
      "Cost after iteration 1880: 0.035487\n",
      "Cost after iteration 1881: 0.035456\n",
      "Cost after iteration 1882: 0.035424\n",
      "Cost after iteration 1883: 0.035393\n",
      "Cost after iteration 1884: 0.035363\n",
      "Cost after iteration 1885: 0.035332\n",
      "Cost after iteration 1886: 0.035301\n",
      "Cost after iteration 1887: 0.035270\n",
      "Cost after iteration 1888: 0.035239\n",
      "Cost after iteration 1889: 0.035208\n",
      "Cost after iteration 1890: 0.035177\n",
      "Cost after iteration 1891: 0.035147\n",
      "Cost after iteration 1892: 0.035116\n",
      "Cost after iteration 1893: 0.035085\n",
      "Cost after iteration 1894: 0.035055\n",
      "Cost after iteration 1895: 0.035024\n",
      "Cost after iteration 1896: 0.034993\n",
      "Cost after iteration 1897: 0.034963\n",
      "Cost after iteration 1898: 0.034932\n",
      "Cost after iteration 1899: 0.034902\n",
      "Cost after iteration 1900: 0.034872\n",
      "Cost after iteration 1901: 0.034841\n",
      "Cost after iteration 1902: 0.034811\n",
      "Cost after iteration 1903: 0.034781\n",
      "Cost after iteration 1904: 0.034750\n",
      "Cost after iteration 1905: 0.034720\n",
      "Cost after iteration 1906: 0.034690\n",
      "Cost after iteration 1907: 0.034660\n",
      "Cost after iteration 1908: 0.034629\n",
      "Cost after iteration 1909: 0.034599\n",
      "Cost after iteration 1910: 0.034569\n",
      "Cost after iteration 1911: 0.034539\n",
      "Cost after iteration 1912: 0.034509\n",
      "Cost after iteration 1913: 0.034479\n",
      "Cost after iteration 1914: 0.034449\n",
      "Cost after iteration 1915: 0.034419\n",
      "Cost after iteration 1916: 0.034389\n",
      "Cost after iteration 1917: 0.034360\n",
      "Cost after iteration 1918: 0.034330\n",
      "Cost after iteration 1919: 0.034300\n",
      "Cost after iteration 1920: 0.034270\n",
      "Cost after iteration 1921: 0.034240\n",
      "Cost after iteration 1922: 0.034211\n",
      "Cost after iteration 1923: 0.034181\n",
      "Cost after iteration 1924: 0.034152\n",
      "Cost after iteration 1925: 0.034122\n",
      "Cost after iteration 1926: 0.034092\n",
      "Cost after iteration 1927: 0.034063\n",
      "Cost after iteration 1928: 0.034033\n",
      "Cost after iteration 1929: 0.034004\n",
      "Cost after iteration 1930: 0.033975\n",
      "Cost after iteration 1931: 0.033945\n",
      "Cost after iteration 1932: 0.033916\n",
      "Cost after iteration 1933: 0.033886\n",
      "Cost after iteration 1934: 0.033857\n",
      "Cost after iteration 1935: 0.033828\n",
      "Cost after iteration 1936: 0.033799\n",
      "Cost after iteration 1937: 0.033769\n",
      "Cost after iteration 1938: 0.033740\n",
      "Cost after iteration 1939: 0.033711\n",
      "Cost after iteration 1940: 0.033682\n",
      "Cost after iteration 1941: 0.033653\n",
      "Cost after iteration 1942: 0.033624\n",
      "Cost after iteration 1943: 0.033595\n",
      "Cost after iteration 1944: 0.033566\n",
      "Cost after iteration 1945: 0.033537\n",
      "Cost after iteration 1946: 0.033508\n",
      "Cost after iteration 1947: 0.033479\n",
      "Cost after iteration 1948: 0.033450\n",
      "Cost after iteration 1949: 0.033422\n",
      "Cost after iteration 1950: 0.033393\n",
      "Cost after iteration 1951: 0.033364\n",
      "Cost after iteration 1952: 0.033335\n",
      "Cost after iteration 1953: 0.033307\n",
      "Cost after iteration 1954: 0.033278\n",
      "Cost after iteration 1955: 0.033250\n",
      "Cost after iteration 1956: 0.033221\n",
      "Cost after iteration 1957: 0.033192\n",
      "Cost after iteration 1958: 0.033164\n",
      "Cost after iteration 1959: 0.033135\n",
      "Cost after iteration 1960: 0.033107\n",
      "Cost after iteration 1961: 0.033078\n",
      "Cost after iteration 1962: 0.033050\n",
      "Cost after iteration 1963: 0.033022\n",
      "Cost after iteration 1964: 0.032993\n",
      "Cost after iteration 1965: 0.032965\n",
      "Cost after iteration 1966: 0.032937\n",
      "Cost after iteration 1967: 0.032909\n",
      "Cost after iteration 1968: 0.032880\n",
      "Cost after iteration 1969: 0.032852\n",
      "Cost after iteration 1970: 0.032824\n",
      "Cost after iteration 1971: 0.032796\n",
      "Cost after iteration 1972: 0.032768\n",
      "Cost after iteration 1973: 0.032740\n",
      "Cost after iteration 1974: 0.032712\n",
      "Cost after iteration 1975: 0.032684\n",
      "Cost after iteration 1976: 0.032656\n",
      "Cost after iteration 1977: 0.032628\n",
      "Cost after iteration 1978: 0.032600\n",
      "Cost after iteration 1979: 0.032572\n",
      "Cost after iteration 1980: 0.032544\n",
      "Cost after iteration 1981: 0.032517\n",
      "Cost after iteration 1982: 0.032489\n",
      "Cost after iteration 1983: 0.032461\n",
      "Cost after iteration 1984: 0.032433\n",
      "Cost after iteration 1985: 0.032406\n",
      "Cost after iteration 1986: 0.032378\n",
      "Cost after iteration 1987: 0.032350\n",
      "Cost after iteration 1988: 0.032323\n",
      "Cost after iteration 1989: 0.032295\n",
      "Cost after iteration 1990: 0.032268\n",
      "Cost after iteration 1991: 0.032240\n",
      "Cost after iteration 1992: 0.032213\n",
      "Cost after iteration 1993: 0.032185\n",
      "Cost after iteration 1994: 0.032158\n",
      "Cost after iteration 1995: 0.032131\n",
      "Cost after iteration 1996: 0.032103\n",
      "Cost after iteration 1997: 0.032076\n",
      "Cost after iteration 1998: 0.032049\n",
      "Cost after iteration 1999: 0.032021\n",
      "Cost after iteration 2000: 0.031994\n",
      "Cost after iteration 2001: 0.031967\n",
      "Cost after iteration 2002: 0.031940\n",
      "Cost after iteration 2003: 0.031913\n",
      "Cost after iteration 2004: 0.031885\n",
      "Cost after iteration 2005: 0.031858\n",
      "Cost after iteration 2006: 0.031831\n",
      "Cost after iteration 2007: 0.031804\n",
      "Cost after iteration 2008: 0.031777\n",
      "Cost after iteration 2009: 0.031750\n",
      "Cost after iteration 2010: 0.031723\n",
      "Cost after iteration 2011: 0.031697\n",
      "Cost after iteration 2012: 0.031670\n",
      "Cost after iteration 2013: 0.031643\n",
      "Cost after iteration 2014: 0.031616\n",
      "Cost after iteration 2015: 0.031589\n",
      "Cost after iteration 2016: 0.031563\n",
      "Cost after iteration 2017: 0.031536\n",
      "Cost after iteration 2018: 0.031509\n",
      "Cost after iteration 2019: 0.031482\n",
      "Cost after iteration 2020: 0.031456\n",
      "Cost after iteration 2021: 0.031429\n",
      "Cost after iteration 2022: 0.031403\n",
      "Cost after iteration 2023: 0.031376\n",
      "Cost after iteration 2024: 0.031350\n",
      "Cost after iteration 2025: 0.031323\n",
      "Cost after iteration 2026: 0.031297\n",
      "Cost after iteration 2027: 0.031270\n",
      "Cost after iteration 2028: 0.031244\n",
      "Cost after iteration 2029: 0.031217\n",
      "Cost after iteration 2030: 0.031191\n",
      "Cost after iteration 2031: 0.031165\n",
      "Cost after iteration 2032: 0.031138\n",
      "Cost after iteration 2033: 0.031112\n",
      "Cost after iteration 2034: 0.031086\n",
      "Cost after iteration 2035: 0.031060\n",
      "Cost after iteration 2036: 0.031034\n",
      "Cost after iteration 2037: 0.031007\n",
      "Cost after iteration 2038: 0.030981\n",
      "Cost after iteration 2039: 0.030955\n",
      "Cost after iteration 2040: 0.030929\n",
      "Cost after iteration 2041: 0.030903\n",
      "Cost after iteration 2042: 0.030877\n",
      "Cost after iteration 2043: 0.030851\n",
      "Cost after iteration 2044: 0.030825\n",
      "Cost after iteration 2045: 0.030799\n",
      "Cost after iteration 2046: 0.030773\n",
      "Cost after iteration 2047: 0.030748\n",
      "Cost after iteration 2048: 0.030722\n",
      "Cost after iteration 2049: 0.030696\n",
      "Cost after iteration 2050: 0.030670\n",
      "Cost after iteration 2051: 0.030644\n",
      "Cost after iteration 2052: 0.030619\n",
      "Cost after iteration 2053: 0.030593\n",
      "Cost after iteration 2054: 0.030567\n",
      "Cost after iteration 2055: 0.030542\n",
      "Cost after iteration 2056: 0.030516\n",
      "Cost after iteration 2057: 0.030491\n",
      "Cost after iteration 2058: 0.030465\n",
      "Cost after iteration 2059: 0.030439\n",
      "Cost after iteration 2060: 0.030414\n",
      "Cost after iteration 2061: 0.030389\n",
      "Cost after iteration 2062: 0.030363\n",
      "Cost after iteration 2063: 0.030338\n",
      "Cost after iteration 2064: 0.030312\n",
      "Cost after iteration 2065: 0.030287\n",
      "Cost after iteration 2066: 0.030262\n",
      "Cost after iteration 2067: 0.030236\n",
      "Cost after iteration 2068: 0.030211\n",
      "Cost after iteration 2069: 0.030186\n",
      "Cost after iteration 2070: 0.030161\n",
      "Cost after iteration 2071: 0.030135\n",
      "Cost after iteration 2072: 0.030110\n",
      "Cost after iteration 2073: 0.030085\n",
      "Cost after iteration 2074: 0.030060\n",
      "Cost after iteration 2075: 0.030035\n",
      "Cost after iteration 2076: 0.030010\n",
      "Cost after iteration 2077: 0.029985\n",
      "Cost after iteration 2078: 0.029960\n",
      "Cost after iteration 2079: 0.029935\n",
      "Cost after iteration 2080: 0.029910\n",
      "Cost after iteration 2081: 0.029885\n",
      "Cost after iteration 2082: 0.029860\n",
      "Cost after iteration 2083: 0.029835\n",
      "Cost after iteration 2084: 0.029810\n",
      "Cost after iteration 2085: 0.029786\n",
      "Cost after iteration 2086: 0.029761\n",
      "Cost after iteration 2087: 0.029736\n",
      "Cost after iteration 2088: 0.029711\n",
      "Cost after iteration 2089: 0.029687\n",
      "Cost after iteration 2090: 0.029662\n",
      "Cost after iteration 2091: 0.029637\n",
      "Cost after iteration 2092: 0.029613\n",
      "Cost after iteration 2093: 0.029588\n",
      "Cost after iteration 2094: 0.029564\n",
      "Cost after iteration 2095: 0.029539\n",
      "Cost after iteration 2096: 0.029514\n",
      "Cost after iteration 2097: 0.029490\n",
      "Cost after iteration 2098: 0.029466\n",
      "Cost after iteration 2099: 0.029441\n",
      "Cost after iteration 2100: 0.029417\n",
      "Cost after iteration 2101: 0.029392\n",
      "Cost after iteration 2102: 0.029368\n",
      "Cost after iteration 2103: 0.029344\n",
      "Cost after iteration 2104: 0.029319\n",
      "Cost after iteration 2105: 0.029295\n",
      "Cost after iteration 2106: 0.029271\n",
      "Cost after iteration 2107: 0.029247\n",
      "Cost after iteration 2108: 0.029222\n",
      "Cost after iteration 2109: 0.029198\n",
      "Cost after iteration 2110: 0.029174\n",
      "Cost after iteration 2111: 0.029150\n",
      "Cost after iteration 2112: 0.029126\n",
      "Cost after iteration 2113: 0.029102\n",
      "Cost after iteration 2114: 0.029078\n",
      "Cost after iteration 2115: 0.029054\n",
      "Cost after iteration 2116: 0.029030\n",
      "Cost after iteration 2117: 0.029006\n",
      "Cost after iteration 2118: 0.028982\n",
      "Cost after iteration 2119: 0.028958\n",
      "Cost after iteration 2120: 0.028934\n",
      "Cost after iteration 2121: 0.028910\n",
      "Cost after iteration 2122: 0.028886\n",
      "Cost after iteration 2123: 0.028863\n",
      "Cost after iteration 2124: 0.028839\n",
      "Cost after iteration 2125: 0.028815\n",
      "Cost after iteration 2126: 0.028791\n",
      "Cost after iteration 2127: 0.028768\n",
      "Cost after iteration 2128: 0.028744\n",
      "Cost after iteration 2129: 0.028720\n",
      "Cost after iteration 2130: 0.028697\n",
      "Cost after iteration 2131: 0.028673\n",
      "Cost after iteration 2132: 0.028649\n",
      "Cost after iteration 2133: 0.028626\n",
      "Cost after iteration 2134: 0.028602\n",
      "Cost after iteration 2135: 0.028579\n",
      "Cost after iteration 2136: 0.028555\n",
      "Cost after iteration 2137: 0.028532\n",
      "Cost after iteration 2138: 0.028509\n",
      "Cost after iteration 2139: 0.028485\n",
      "Cost after iteration 2140: 0.028462\n",
      "Cost after iteration 2141: 0.028438\n",
      "Cost after iteration 2142: 0.028415\n",
      "Cost after iteration 2143: 0.028392\n",
      "Cost after iteration 2144: 0.028368\n",
      "Cost after iteration 2145: 0.028345\n",
      "Cost after iteration 2146: 0.028322\n",
      "Cost after iteration 2147: 0.028299\n",
      "Cost after iteration 2148: 0.028276\n",
      "Cost after iteration 2149: 0.028253\n",
      "Cost after iteration 2150: 0.028229\n",
      "Cost after iteration 2151: 0.028206\n",
      "Cost after iteration 2152: 0.028183\n",
      "Cost after iteration 2153: 0.028160\n",
      "Cost after iteration 2154: 0.028137\n",
      "Cost after iteration 2155: 0.028114\n",
      "Cost after iteration 2156: 0.028091\n",
      "Cost after iteration 2157: 0.028068\n",
      "Cost after iteration 2158: 0.028045\n",
      "Cost after iteration 2159: 0.028022\n",
      "Cost after iteration 2160: 0.028000\n",
      "Cost after iteration 2161: 0.027977\n",
      "Cost after iteration 2162: 0.027954\n",
      "Cost after iteration 2163: 0.027931\n",
      "Cost after iteration 2164: 0.027908\n",
      "Cost after iteration 2165: 0.027886\n",
      "Cost after iteration 2166: 0.027863\n",
      "Cost after iteration 2167: 0.027840\n",
      "Cost after iteration 2168: 0.027817\n",
      "Cost after iteration 2169: 0.027795\n",
      "Cost after iteration 2170: 0.027772\n",
      "Cost after iteration 2171: 0.027750\n",
      "Cost after iteration 2172: 0.027727\n",
      "Cost after iteration 2173: 0.027704\n",
      "Cost after iteration 2174: 0.027682\n",
      "Cost after iteration 2175: 0.027659\n",
      "Cost after iteration 2176: 0.027637\n",
      "Cost after iteration 2177: 0.027614\n",
      "Cost after iteration 2178: 0.027592\n",
      "Cost after iteration 2179: 0.027570\n",
      "Cost after iteration 2180: 0.027547\n",
      "Cost after iteration 2181: 0.027525\n",
      "Cost after iteration 2182: 0.027502\n",
      "Cost after iteration 2183: 0.027480\n",
      "Cost after iteration 2184: 0.027458\n",
      "Cost after iteration 2185: 0.027436\n",
      "Cost after iteration 2186: 0.027413\n",
      "Cost after iteration 2187: 0.027391\n",
      "Cost after iteration 2188: 0.027369\n",
      "Cost after iteration 2189: 0.027347\n",
      "Cost after iteration 2190: 0.027325\n",
      "Cost after iteration 2191: 0.027303\n",
      "Cost after iteration 2192: 0.027280\n",
      "Cost after iteration 2193: 0.027258\n",
      "Cost after iteration 2194: 0.027236\n",
      "Cost after iteration 2195: 0.027214\n",
      "Cost after iteration 2196: 0.027192\n",
      "Cost after iteration 2197: 0.027170\n",
      "Cost after iteration 2198: 0.027148\n",
      "Cost after iteration 2199: 0.027126\n",
      "Cost after iteration 2200: 0.027104\n",
      "Cost after iteration 2201: 0.027083\n",
      "Cost after iteration 2202: 0.027061\n",
      "Cost after iteration 2203: 0.027039\n",
      "Cost after iteration 2204: 0.027017\n",
      "Cost after iteration 2205: 0.026995\n",
      "Cost after iteration 2206: 0.026973\n",
      "Cost after iteration 2207: 0.026952\n",
      "Cost after iteration 2208: 0.026930\n",
      "Cost after iteration 2209: 0.026908\n",
      "Cost after iteration 2210: 0.026887\n",
      "Cost after iteration 2211: 0.026865\n",
      "Cost after iteration 2212: 0.026843\n",
      "Cost after iteration 2213: 0.026822\n",
      "Cost after iteration 2214: 0.026800\n",
      "Cost after iteration 2215: 0.026779\n",
      "Cost after iteration 2216: 0.026757\n",
      "Cost after iteration 2217: 0.026736\n",
      "Cost after iteration 2218: 0.026714\n",
      "Cost after iteration 2219: 0.026693\n",
      "Cost after iteration 2220: 0.026671\n",
      "Cost after iteration 2221: 0.026650\n",
      "Cost after iteration 2222: 0.026628\n",
      "Cost after iteration 2223: 0.026607\n",
      "Cost after iteration 2224: 0.026586\n",
      "Cost after iteration 2225: 0.026564\n",
      "Cost after iteration 2226: 0.026543\n",
      "Cost after iteration 2227: 0.026522\n",
      "Cost after iteration 2228: 0.026500\n",
      "Cost after iteration 2229: 0.026479\n",
      "Cost after iteration 2230: 0.026458\n",
      "Cost after iteration 2231: 0.026437\n",
      "Cost after iteration 2232: 0.026416\n",
      "Cost after iteration 2233: 0.026394\n",
      "Cost after iteration 2234: 0.026373\n",
      "Cost after iteration 2235: 0.026352\n",
      "Cost after iteration 2236: 0.026331\n",
      "Cost after iteration 2237: 0.026310\n",
      "Cost after iteration 2238: 0.026289\n",
      "Cost after iteration 2239: 0.026268\n",
      "Cost after iteration 2240: 0.026247\n",
      "Cost after iteration 2241: 0.026226\n",
      "Cost after iteration 2242: 0.026205\n",
      "Cost after iteration 2243: 0.026184\n",
      "Cost after iteration 2244: 0.026163\n",
      "Cost after iteration 2245: 0.026142\n",
      "Cost after iteration 2246: 0.026122\n",
      "Cost after iteration 2247: 0.026101\n",
      "Cost after iteration 2248: 0.026080\n",
      "Cost after iteration 2249: 0.026059\n",
      "Cost after iteration 2250: 0.026038\n",
      "Cost after iteration 2251: 0.026018\n",
      "Cost after iteration 2252: 0.025997\n",
      "Cost after iteration 2253: 0.025976\n",
      "Cost after iteration 2254: 0.025956\n",
      "Cost after iteration 2255: 0.025935\n",
      "Cost after iteration 2256: 0.025914\n",
      "Cost after iteration 2257: 0.025894\n",
      "Cost after iteration 2258: 0.025873\n",
      "Cost after iteration 2259: 0.025852\n",
      "Cost after iteration 2260: 0.025832\n",
      "Cost after iteration 2261: 0.025811\n",
      "Cost after iteration 2262: 0.025791\n",
      "Cost after iteration 2263: 0.025770\n",
      "Cost after iteration 2264: 0.025750\n",
      "Cost after iteration 2265: 0.025730\n",
      "Cost after iteration 2266: 0.025709\n",
      "Cost after iteration 2267: 0.025689\n",
      "Cost after iteration 2268: 0.025668\n",
      "Cost after iteration 2269: 0.025648\n",
      "Cost after iteration 2270: 0.025628\n",
      "Cost after iteration 2271: 0.025607\n",
      "Cost after iteration 2272: 0.025587\n",
      "Cost after iteration 2273: 0.025567\n",
      "Cost after iteration 2274: 0.025547\n",
      "Cost after iteration 2275: 0.025526\n",
      "Cost after iteration 2276: 0.025506\n",
      "Cost after iteration 2277: 0.025486\n",
      "Cost after iteration 2278: 0.025466\n",
      "Cost after iteration 2279: 0.025446\n",
      "Cost after iteration 2280: 0.025426\n",
      "Cost after iteration 2281: 0.025405\n",
      "Cost after iteration 2282: 0.025385\n",
      "Cost after iteration 2283: 0.025365\n",
      "Cost after iteration 2284: 0.025345\n",
      "Cost after iteration 2285: 0.025325\n",
      "Cost after iteration 2286: 0.025305\n",
      "Cost after iteration 2287: 0.025285\n",
      "Cost after iteration 2288: 0.025265\n",
      "Cost after iteration 2289: 0.025246\n",
      "Cost after iteration 2290: 0.025226\n",
      "Cost after iteration 2291: 0.025206\n",
      "Cost after iteration 2292: 0.025186\n",
      "Cost after iteration 2293: 0.025166\n",
      "Cost after iteration 2294: 0.025146\n",
      "Cost after iteration 2295: 0.025126\n",
      "Cost after iteration 2296: 0.025107\n",
      "Cost after iteration 2297: 0.025087\n",
      "Cost after iteration 2298: 0.025067\n",
      "Cost after iteration 2299: 0.025048\n",
      "Cost after iteration 2300: 0.025028\n",
      "Cost after iteration 2301: 0.025008\n",
      "Cost after iteration 2302: 0.024989\n",
      "Cost after iteration 2303: 0.024969\n",
      "Cost after iteration 2304: 0.024949\n",
      "Cost after iteration 2305: 0.024930\n",
      "Cost after iteration 2306: 0.024910\n",
      "Cost after iteration 2307: 0.024891\n",
      "Cost after iteration 2308: 0.024871\n",
      "Cost after iteration 2309: 0.024852\n",
      "Cost after iteration 2310: 0.024832\n",
      "Cost after iteration 2311: 0.024813\n",
      "Cost after iteration 2312: 0.024793\n",
      "Cost after iteration 2313: 0.024774\n",
      "Cost after iteration 2314: 0.024754\n",
      "Cost after iteration 2315: 0.024735\n",
      "Cost after iteration 2316: 0.024716\n",
      "Cost after iteration 2317: 0.024696\n",
      "Cost after iteration 2318: 0.024677\n",
      "Cost after iteration 2319: 0.024658\n",
      "Cost after iteration 2320: 0.024638\n",
      "Cost after iteration 2321: 0.024619\n",
      "Cost after iteration 2322: 0.024600\n",
      "Cost after iteration 2323: 0.024581\n",
      "Cost after iteration 2324: 0.024562\n",
      "Cost after iteration 2325: 0.024542\n",
      "Cost after iteration 2326: 0.024523\n",
      "Cost after iteration 2327: 0.024504\n",
      "Cost after iteration 2328: 0.024485\n",
      "Cost after iteration 2329: 0.024466\n",
      "Cost after iteration 2330: 0.024447\n",
      "Cost after iteration 2331: 0.024428\n",
      "Cost after iteration 2332: 0.024409\n",
      "Cost after iteration 2333: 0.024390\n",
      "Cost after iteration 2334: 0.024371\n",
      "Cost after iteration 2335: 0.024352\n",
      "Cost after iteration 2336: 0.024333\n",
      "Cost after iteration 2337: 0.024314\n",
      "Cost after iteration 2338: 0.024295\n",
      "Cost after iteration 2339: 0.024276\n",
      "Cost after iteration 2340: 0.024257\n",
      "Cost after iteration 2341: 0.024238\n",
      "Cost after iteration 2342: 0.024220\n",
      "Cost after iteration 2343: 0.024201\n",
      "Cost after iteration 2344: 0.024182\n",
      "Cost after iteration 2345: 0.024163\n",
      "Cost after iteration 2346: 0.024144\n",
      "Cost after iteration 2347: 0.024126\n",
      "Cost after iteration 2348: 0.024107\n",
      "Cost after iteration 2349: 0.024088\n",
      "Cost after iteration 2350: 0.024070\n",
      "Cost after iteration 2351: 0.024051\n",
      "Cost after iteration 2352: 0.024032\n",
      "Cost after iteration 2353: 0.024014\n",
      "Cost after iteration 2354: 0.023995\n",
      "Cost after iteration 2355: 0.023977\n",
      "Cost after iteration 2356: 0.023958\n",
      "Cost after iteration 2357: 0.023940\n",
      "Cost after iteration 2358: 0.023921\n",
      "Cost after iteration 2359: 0.023903\n",
      "Cost after iteration 2360: 0.023884\n",
      "Cost after iteration 2361: 0.023866\n",
      "Cost after iteration 2362: 0.023847\n",
      "Cost after iteration 2363: 0.023829\n",
      "Cost after iteration 2364: 0.023810\n",
      "Cost after iteration 2365: 0.023792\n",
      "Cost after iteration 2366: 0.023774\n",
      "Cost after iteration 2367: 0.023755\n",
      "Cost after iteration 2368: 0.023737\n",
      "Cost after iteration 2369: 0.023719\n",
      "Cost after iteration 2370: 0.023700\n",
      "Cost after iteration 2371: 0.023682\n",
      "Cost after iteration 2372: 0.023664\n",
      "Cost after iteration 2373: 0.023646\n",
      "Cost after iteration 2374: 0.023628\n",
      "Cost after iteration 2375: 0.023609\n",
      "Cost after iteration 2376: 0.023591\n",
      "Cost after iteration 2377: 0.023573\n",
      "Cost after iteration 2378: 0.023555\n",
      "Cost after iteration 2379: 0.023537\n",
      "Cost after iteration 2380: 0.023519\n",
      "Cost after iteration 2381: 0.023501\n",
      "Cost after iteration 2382: 0.023483\n",
      "Cost after iteration 2383: 0.023465\n",
      "Cost after iteration 2384: 0.023447\n",
      "Cost after iteration 2385: 0.023429\n",
      "Cost after iteration 2386: 0.023411\n",
      "Cost after iteration 2387: 0.023393\n",
      "Cost after iteration 2388: 0.023375\n",
      "Cost after iteration 2389: 0.023357\n",
      "Cost after iteration 2390: 0.023339\n",
      "Cost after iteration 2391: 0.023321\n",
      "Cost after iteration 2392: 0.023303\n",
      "Cost after iteration 2393: 0.023285\n",
      "Cost after iteration 2394: 0.023268\n",
      "Cost after iteration 2395: 0.023250\n",
      "Cost after iteration 2396: 0.023232\n",
      "Cost after iteration 2397: 0.023214\n",
      "Cost after iteration 2398: 0.023197\n",
      "Cost after iteration 2399: 0.023179\n",
      "Cost after iteration 2400: 0.023161\n",
      "Cost after iteration 2401: 0.023143\n",
      "Cost after iteration 2402: 0.023126\n",
      "Cost after iteration 2403: 0.023108\n",
      "Cost after iteration 2404: 0.023090\n",
      "Cost after iteration 2405: 0.023073\n",
      "Cost after iteration 2406: 0.023055\n",
      "Cost after iteration 2407: 0.023038\n",
      "Cost after iteration 2408: 0.023020\n",
      "Cost after iteration 2409: 0.023003\n",
      "Cost after iteration 2410: 0.022985\n",
      "Cost after iteration 2411: 0.022968\n",
      "Cost after iteration 2412: 0.022950\n",
      "Cost after iteration 2413: 0.022933\n",
      "Cost after iteration 2414: 0.022915\n",
      "Cost after iteration 2415: 0.022898\n",
      "Cost after iteration 2416: 0.022880\n",
      "Cost after iteration 2417: 0.022863\n",
      "Cost after iteration 2418: 0.022846\n",
      "Cost after iteration 2419: 0.022828\n",
      "Cost after iteration 2420: 0.022811\n",
      "Cost after iteration 2421: 0.022794\n",
      "Cost after iteration 2422: 0.022776\n",
      "Cost after iteration 2423: 0.022759\n",
      "Cost after iteration 2424: 0.022742\n",
      "Cost after iteration 2425: 0.022725\n",
      "Cost after iteration 2426: 0.022707\n",
      "Cost after iteration 2427: 0.022690\n",
      "Cost after iteration 2428: 0.022673\n",
      "Cost after iteration 2429: 0.022656\n",
      "Cost after iteration 2430: 0.022639\n",
      "Cost after iteration 2431: 0.022621\n",
      "Cost after iteration 2432: 0.022604\n",
      "Cost after iteration 2433: 0.022587\n",
      "Cost after iteration 2434: 0.022570\n",
      "Cost after iteration 2435: 0.022553\n",
      "Cost after iteration 2436: 0.022536\n",
      "Cost after iteration 2437: 0.022519\n",
      "Cost after iteration 2438: 0.022502\n",
      "Cost after iteration 2439: 0.022485\n",
      "Cost after iteration 2440: 0.022468\n",
      "Cost after iteration 2441: 0.022451\n",
      "Cost after iteration 2442: 0.022434\n",
      "Cost after iteration 2443: 0.022417\n",
      "Cost after iteration 2444: 0.022400\n",
      "Cost after iteration 2445: 0.022383\n",
      "Cost after iteration 2446: 0.022367\n",
      "Cost after iteration 2447: 0.022350\n",
      "Cost after iteration 2448: 0.022333\n",
      "Cost after iteration 2449: 0.022316\n",
      "Cost after iteration 2450: 0.022299\n",
      "Cost after iteration 2451: 0.022283\n",
      "Cost after iteration 2452: 0.022266\n",
      "Cost after iteration 2453: 0.022249\n",
      "Cost after iteration 2454: 0.022232\n",
      "Cost after iteration 2455: 0.022216\n",
      "Cost after iteration 2456: 0.022199\n",
      "Cost after iteration 2457: 0.022182\n",
      "Cost after iteration 2458: 0.022166\n",
      "Cost after iteration 2459: 0.022149\n",
      "Cost after iteration 2460: 0.022132\n",
      "Cost after iteration 2461: 0.022116\n",
      "Cost after iteration 2462: 0.022099\n",
      "Cost after iteration 2463: 0.022083\n",
      "Cost after iteration 2464: 0.022066\n",
      "Cost after iteration 2465: 0.022050\n",
      "Cost after iteration 2466: 0.022033\n",
      "Cost after iteration 2467: 0.022017\n",
      "Cost after iteration 2468: 0.022000\n",
      "Cost after iteration 2469: 0.021984\n",
      "Cost after iteration 2470: 0.021967\n",
      "Cost after iteration 2471: 0.021951\n",
      "Cost after iteration 2472: 0.021934\n",
      "Cost after iteration 2473: 0.021918\n",
      "Cost after iteration 2474: 0.021902\n",
      "Cost after iteration 2475: 0.021885\n",
      "Cost after iteration 2476: 0.021869\n",
      "Cost after iteration 2477: 0.021853\n",
      "Cost after iteration 2478: 0.021836\n",
      "Cost after iteration 2479: 0.021820\n",
      "Cost after iteration 2480: 0.021804\n",
      "Cost after iteration 2481: 0.021787\n",
      "Cost after iteration 2482: 0.021771\n",
      "Cost after iteration 2483: 0.021755\n",
      "Cost after iteration 2484: 0.021739\n",
      "Cost after iteration 2485: 0.021723\n",
      "Cost after iteration 2486: 0.021706\n",
      "Cost after iteration 2487: 0.021690\n",
      "Cost after iteration 2488: 0.021674\n",
      "Cost after iteration 2489: 0.021658\n",
      "Cost after iteration 2490: 0.021642\n",
      "Cost after iteration 2491: 0.021626\n",
      "Cost after iteration 2492: 0.021610\n",
      "Cost after iteration 2493: 0.021594\n",
      "Cost after iteration 2494: 0.021578\n",
      "Cost after iteration 2495: 0.021562\n",
      "Cost after iteration 2496: 0.021546\n",
      "Cost after iteration 2497: 0.021530\n",
      "Cost after iteration 2498: 0.021514\n",
      "Cost after iteration 2499: 0.021498\n"
     ]
    }
   ],
   "source": [
    "parameters, cost_list = model_training(X_train_flat,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be0e3cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(cost_list)),cost_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b362b9",
   "metadata": {},
   "source": [
    "### Making predictions\n",
    "\n",
    "We don't just want to train a neural network, we also want to use it to make predictions. For this purpose, we create a `predict` function, that takes an input X, as well as the parameters of the trained model.\n",
    "\n",
    "Don't worry about computing the prediction - we have already done so, when we implemented the forward propagation. Note that forward propagation takes as input both an `X` and a `y`, but we don't care about the cost (only about the `yHat = cache['A2']`, so we can give an empty `y`, as long as it has the correct shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6b97116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,parameters):\n",
    "    _, cache = forward_propagation(X,np.zeros((X.shape[0],1)),parameters)\n",
    "    yHat = cache['A2']    # Get yHat from the cache\n",
    "    y_prediction = (yHat > 0.5)      # Make a prediction - when yHat > 0.5, assume 1, otherwise 0\n",
    "    return y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702bc17c",
   "metadata": {},
   "source": [
    "Let's see how well our predictions perform, both on the training set and the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8dd72c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 99.7134670487106 %\n",
      "test accuracy: 95.16129032258064 %\n"
     ]
    }
   ],
   "source": [
    "y_prediction_test = predict(X_test_flat,parameters)\n",
    "y_prediction_train = predict(X_train_flat,parameters)\n",
    "\n",
    "print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100))\n",
    "print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778caba",
   "metadata": {},
   "source": [
    "Getting there! Certainly some overfitting happening, but 95% test accuracy is not bad at all."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
