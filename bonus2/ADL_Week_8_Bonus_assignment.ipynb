{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoQ-zQ1WeuB9"
      },
      "source": [
        "# Building a semantic segmentation algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-u0bx0keacm"
      },
      "source": [
        "This notebook is based on Francois Chollet, \"Deep Learning with Python\". The idea is to build an image segmentation algorithm. There are not many publicly available datasets for this task. One of the few ones is the [The Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/), which contains images 37 (pet) categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "eiXUA7Jte3sq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMvXNdC6m0RE"
      },
      "source": [
        "First, we load the dataset and sort the images and annotations into folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HtfZTduxeacr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: wget: command not found\n",
            "/bin/bash: wget: command not found\n",
            "tar: Error opening archive: Failed to open 'images.tar.gz'\n",
            "tar: Error opening archive: Failed to open 'annotations.tar.gz'\n"
          ]
        }
      ],
      "source": [
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
        "!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
        "!tar -xf images.tar.gz\n",
        "!tar -xf annotations.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Z5gZ9EYLeacr"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'images/'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768 Applied Deep Learning /Bonus2/ADL_Week_8_Bonus_assignment.ipynb Cell 6\u001b[0m in \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m input_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mimages/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m target_dir \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mannotations/trimaps/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m input_img_paths \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(input_dir, fname)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m      \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(input_dir)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m      \u001b[39mif\u001b[39;00m fname\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.jpg\u001b[39m\u001b[39m\"\u001b[39m)])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m target_paths \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     [os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(target_dir, fname)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m      \u001b[39mfor\u001b[39;00m fname \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(target_dir)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m      \u001b[39mif\u001b[39;00m fname\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.png\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m fname\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)])\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/'"
          ]
        }
      ],
      "source": [
        "input_dir = \"images/\"\n",
        "target_dir = \"annotations/trimaps/\"\n",
        "\n",
        "input_img_paths = sorted(\n",
        "    [os.path.join(input_dir, fname)\n",
        "     for fname in os.listdir(input_dir)\n",
        "     if fname.endswith(\".jpg\")])\n",
        "target_paths = sorted(\n",
        "    [os.path.join(target_dir, fname)\n",
        "     for fname in os.listdir(target_dir)\n",
        "     if fname.endswith(\".png\") and not fname.startswith(\".\")])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-YLowl5m5VM"
      },
      "source": [
        "We can then take a look at examples. First, the original image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6nu0M6B0eacs"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'input_img_paths' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768 Applied Deep Learning /Bonus2/ADL_Week_8_Bonus_assignment.ipynb Cell 8\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m plt\u001b[39m.\u001b[39maxis(\u001b[39m\"\u001b[39m\u001b[39moff\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(load_img(input_img_paths[\u001b[39m9\u001b[39m]))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_img_paths' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.axis(\"off\")\n",
        "plt.imshow(load_img(input_img_paths[9]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnvPDaRtnB9p"
      },
      "source": [
        "Second, the annotation. Note that each pixel is annotated with a corresponding class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ID1O9gZreacs"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'target_paths' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768 Applied Deep Learning /Bonus2/ADL_Week_8_Bonus_assignment.ipynb Cell 10\u001b[0m in \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     plt\u001b[39m.\u001b[39maxis(\u001b[39m\"\u001b[39m\u001b[39moff\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     plt\u001b[39m.\u001b[39mimshow(normalized_array[:, :, \u001b[39m0\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m img \u001b[39m=\u001b[39m img_to_array(load_img(target_paths[\u001b[39m9\u001b[39m], color_mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgrayscale\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m display_target(img)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'target_paths' is not defined"
          ]
        }
      ],
      "source": [
        "def display_target(target_array):\n",
        "    normalized_array = (target_array.astype(\"uint8\") - 1) * 127\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(normalized_array[:, :, 0])\n",
        "\n",
        "img = img_to_array(load_img(target_paths[9], color_mode=\"grayscale\"))\n",
        "display_target(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeJZTl4onQXq"
      },
      "source": [
        "We now convert the images into numpy arrays that we will use for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Y53AdxkZeact"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'input_img_paths' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768 Applied Deep Learning /Bonus2/ADL_Week_8_Bonus_assignment.ipynb Cell 12\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m img_size \u001b[39m=\u001b[39m (\u001b[39m200\u001b[39m, \u001b[39m200\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m num_imgs \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(input_img_paths)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m random\u001b[39m.\u001b[39mRandom(\u001b[39m1337\u001b[39m)\u001b[39m.\u001b[39mshuffle(input_img_paths)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m random\u001b[39m.\u001b[39mRandom(\u001b[39m1337\u001b[39m)\u001b[39m.\u001b[39mshuffle(target_paths)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_img_paths' is not defined"
          ]
        }
      ],
      "source": [
        "img_size = (200, 200)\n",
        "num_imgs = len(input_img_paths)\n",
        "\n",
        "random.Random(1337).shuffle(input_img_paths)\n",
        "random.Random(1337).shuffle(target_paths)\n",
        "\n",
        "def path_to_input_image(path):\n",
        "    return img_to_array(load_img(path, target_size=img_size))\n",
        "\n",
        "def path_to_target(path):\n",
        "    img = img_to_array(\n",
        "        load_img(path, target_size=img_size, color_mode=\"grayscale\"))\n",
        "    img = img.astype(\"uint8\") - 1\n",
        "    return img\n",
        "\n",
        "input_imgs = np.zeros((num_imgs,) + img_size + (3,), dtype=\"float32\")\n",
        "targets = np.zeros((num_imgs,) + img_size + (1,), dtype=\"uint8\")\n",
        "for i in range(num_imgs):\n",
        "    input_imgs[i] = path_to_input_image(input_img_paths[i])\n",
        "    targets[i] = path_to_target(target_paths[i])\n",
        "\n",
        "num_val_samples = 1000\n",
        "train_input_imgs = input_imgs[:-num_val_samples]\n",
        "train_targets = targets[:-num_val_samples]\n",
        "val_input_imgs = input_imgs[-num_val_samples:]\n",
        "val_targets = targets[-num_val_samples:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyCAd7N_ncMx"
      },
      "source": [
        "Take a look at the dimensions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fEOgHipqnSsL"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_input_imgs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768 Applied Deep Learning /Bonus2/ADL_Week_8_Bonus_assignment.ipynb Cell 14\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(train_input_imgs\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(train_targets\u001b[39m.\u001b[39mshape)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_input_imgs' is not defined"
          ]
        }
      ],
      "source": [
        "print(train_input_imgs.shape)\n",
        "print(train_targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plzQ1SymneFI"
      },
      "source": [
        "In particular, each \"target\" is a two-dimensional map of classes with the same size as the input image. For each input pixel (which comes in three colors, that's why there are three channels in the input), there is exactly one class (this is why there is only one channel)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rDEMI5knylX"
      },
      "source": [
        "We now create our initial model. The first part is a \"normal\" CNN that takes our input and creates an encoding, by \"downsampling\" our input, that is, by going from the full 200x200 image with three channels to a final convolutional layer with dimensions 25x25 and 256 channels.\n",
        "\n",
        "The second part is where things get more interesting. This \"upsamples\" our encoding, to recreate a 2D-output (basically the same image as before, just a schematic version, where pixels are classes rather than actual pixels). Upsampling happens with `Conv2DTranspose` layers, which basically invert what the `Conv2D` layers do.\n",
        "\n",
        "We are creating an encoding from an input, then decoding this encoding into an output of the same dimensions as the original input. Does this sound familiar?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pRVr2Y2_eact"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1 Pro\n",
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-27 14:32:42.644681: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-03-27 14:32:42.644814: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 200, 200, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 100, 100, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 100, 100, 64)      36928     \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 50, 50, 128)       73856     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 50, 50, 128)       147584    \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 25, 25, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 25, 25, 256)       590080    \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTra  (None, 25, 25, 256)      590080    \n",
            " nspose)                                                         \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2DT  (None, 50, 50, 256)      590080    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2DT  (None, 50, 50, 128)      295040    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_3 (Conv2DT  (None, 100, 100, 128)    147584    \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_4 (Conv2DT  (None, 100, 100, 64)     73792     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_transpose_5 (Conv2DT  (None, 200, 200, 64)     36928     \n",
            " ranspose)                                                       \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 200, 200, 3)       1731      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,880,643\n",
            "Trainable params: 2,880,643\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "def get_model(img_size, num_classes):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=img_size + (3,)),\n",
        "        layers.Rescaling(1./255),\n",
        "        layers.Conv2D(64, 3, strides=2, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv2D(128, 3, strides=2, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv2D(256, 3, strides=2, padding=\"same\", activation=\"relu\"),\n",
        "        layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "        \n",
        "        layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv2DTranspose(256, 3, activation=\"relu\", padding=\"same\", strides=2),\n",
        "        layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv2DTranspose(128, 3, activation=\"relu\", padding=\"same\", strides=2),\n",
        "        layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\"),\n",
        "        layers.Conv2DTranspose(64, 3, activation=\"relu\", padding=\"same\", strides=2),\n",
        "        layers.Conv2D(num_classes, 3, activation=\"softmax\", padding=\"same\")])\n",
        "    return model\n",
        "\n",
        "model = get_model(img_size=img_size, num_classes=3)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptgsDTIBpYox"
      },
      "source": [
        "**Question 1**: In your own words, explain what type of model we are creating here. What is the key difference to other models of this type that we have seen so far?\n",
        "\n",
        "**Question 2**: You might notice that we are not using MaxPooling to \"downsample\" (that is, to reduce the size of the layers while increasing the number of channels). Rather, we added strides >1 to our convolutions. Why do you think this is?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nPUuZGroR6R"
      },
      "source": [
        "We next compile and train the model. Note that it will take very long without a GPU, so Colab is recommended. However, you will eventually run out of memory on Colab, so your session will crash. Hence, I highly recommend saving the best model so far (this is already handled with the `ModelCheckpoint`), then starting from that model and keeping on training in a new session. Hence, once your initial model has been created and trained for a few epochs, you can instead use\n",
        "\n",
        "`model = tf.keras.models.load_model(\"oxford_segmentation\")`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "xJVOTZdEeacu"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'train_input_imgs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768 Applied Deep Learning /Bonus2/ADL_Week_8_Bonus_assignment.ipynb Cell 20\u001b[0m in \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrmsprop\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mModelCheckpoint(\u001b[39m\"\u001b[39m\u001b[39moxford_segmentation\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                     save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X25sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mfit(train_input_imgs, train_targets,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X25sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                     epochs\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X25sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                     callbacks\u001b[39m=\u001b[39mcallbacks,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X25sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                     batch_size\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X25sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                     validation_data\u001b[39m=\u001b[39m(val_input_imgs, val_targets))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_input_imgs' is not defined"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"sparse_categorical_crossentropy\")\n",
        "\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\"oxford_segmentation\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "\n",
        "history = model.fit(train_input_imgs, train_targets,\n",
        "                    epochs=30,\n",
        "                    callbacks=callbacks,\n",
        "                    batch_size=64,\n",
        "                    validation_data=(val_input_imgs, val_targets))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0nH_00Qqsrv"
      },
      "source": [
        "**Question 3**: Why do you think are we using `\"sparse_categorical_crossentropy\"` as a loss function?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP6UINQRpQjG"
      },
      "source": [
        "Let's take a look at the predictions made by our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "tdfLZNDYeacu"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "No file or directory found at oxford_segmentation",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32m/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768 Applied Deep Learning /Bonus2/ADL_Week_8_Bonus_assignment.ipynb Cell 23\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(\u001b[39m\"\u001b[39m\u001b[39moxford_segmentation\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m test_image \u001b[39m=\u001b[39m val_input_imgs[i]\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/saving/save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         )\n\u001b[1;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    231\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[1;32m    232\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[1;32m    233\u001b[0m         )\n",
            "\u001b[0;31mOSError\u001b[0m: No file or directory found at oxford_segmentation"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model(\"oxford_segmentation\")\n",
        "\n",
        "i = 4\n",
        "test_image = val_input_imgs[i]\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(array_to_img(test_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9_Ms6fR5yJ7Y"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_image' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768 Applied Deep Learning /Bonus2/ADL_Week_8_Bonus_assignment.ipynb Cell 24\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mask \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39mexpand_dims(test_image, \u001b[39m0\u001b[39m))[\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdisplay_mask\u001b[39m(pred):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pengjunming/StudyInfos/Master/Bayes/Term2/SMM768%20Applied%20Deep%20Learning%20/Bonus2/ADL_Week_8_Bonus_assignment.ipynb#X32sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(pred, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_image' is not defined"
          ]
        }
      ],
      "source": [
        "mask = model.predict(np.expand_dims(test_image, 0))[0]\n",
        "\n",
        "def display_mask(pred):\n",
        "    mask = np.argmax(pred, axis=-1)\n",
        "    mask *= 127\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(mask)\n",
        "\n",
        "display_mask(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDiSBdHVplkt"
      },
      "source": [
        "**Question 4**: U-Net is a model designed for image segmentation. One of the ideas is to have residual connections between downsampling and upsampling blocks (see also the video materials). Can you improve the performance by adding such residual connections to the model above? Note that you will have to use the Functional API to make this work, as in the tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDhE5KxJpoBW"
      },
      "source": [
        "**Question 5**: Can you do better using transfer learning? There are two approaches:\n",
        "\n",
        "1. Use a [pre-trained semantic segmentation model from the TensorFlow hub](https://tfhub.dev/s?module-type=image-segmentation). The advantage is that the models come out-of the box. The disadvantage is that these are user-generated, so they are a bit harder to implement and they may not be trained on data that has a lot of resemblence to pet-pictures.\n",
        "1. Build a \"U-Net\"-like model (see the video materials), by using a pre-made CNN for encoding (a standard one such as Xception or VGG19 should do the trick), and adding a decoding part, including residual connections.\n",
        "\n",
        "When training the models on your data, make sure to freeze as much as possible.\n",
        "\n",
        "Note: neither option is very straightforward. You do not need to have a complete and working network to pass the Bonus Assignment. Instead, your code has to show that you have understood the approach you are attempting and are on the right track."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
